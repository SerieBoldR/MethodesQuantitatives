{"title":"Relation entre une variable qualitative et une variable quantitative","markdown":{"headingText":"Relation entre une variable qualitative et une variable quantitative","headingAttr":{"id":"sec-chap06","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\nDans le cadre de ce chapitre, nous présentons les principales méthodes permettant d'explorer les associations entre une variable quantitative et une variable qualitative avec deux modalités (tests de Student, de Welch et de Wilcoxon) ou avec plus de deux modalités (ANOVA et test de Kruskal-Wallis).\n\n::: bloc_package\n::: bloc_package-header\n::: bloc_package-icon\n:::\n**Liste des *packages* utilisés dans ce chapitre**\n:::\n::: bloc_package-body\n\n* Pour créer des graphiques :\n  - `ggplot2`, le seul, l’unique!\n  - `ggpubr` pour combiner des graphiques.\n* Pour manipuler des données : \n  - `dplyr`, avec les fonctions `group_by`, `summarize` et les pipes `%>%`.\n* Pour les test *t* : \n  - `sjstats` pour réaliser des tests *t* pondérés.\n  - `effectsize` pour calculer les tailles d'effet de tests *t*.\n* Pour la section sur les ANOVA : \n  - `car` pour les ANOVA classiques.\n  - `lmtest` pour le test de Breusch-Pagan d'homogénéité des variances.\n  - `rstatix` intégrant de nombreux tests classiques (comme le test de Shapiro) avec `tidyverse`.\n* Autre *package* : \n  - `foreign` pour importer des fichiers externes.\n:::\n:::\n\n\n## Relation entre une variable quantitative et une variable qualitative à deux modalités {#sec-061}\n::: bloc_objectif\n::: bloc_objectif-header\n::: bloc_objectif-icon\n:::\n**Les moyennes de deux groupes de population sont-elles significativement différentes?**\n:::\n::: bloc_objectif-body\nNous souhaitons ici comparer deux groupes de population en fonction d'une variable continue. \nPar exemple, pour deux échantillons respectivement d'hommes et de femmes travaillant dans le même secteur d'activité, nous pourrions souhaiter vérifier si les moyennes des salaires des hommes et des femmes sont différentes et ainsi vérifier la présence ou l'absence d'une iniquité systématique. En études urbaines, dans le cadre d'une étude sur un espace public, nous pourrions vouloir vérifier si la différence des moyennes du sentiment de sécurité des femmes et des hommes est significative (c'est-à-dire différente de 0).\n\n**Pour un même groupe, la moyenne de la différence d'un phénomène donné mesuré à deux moments est-elle ou non égale à zéro?** \n\nAutrement dit, nous cherchons à comparer un même groupe d'individus avant et après une expérimentation ou dans deux contextes différents. Prenons un exemple d'application en études urbaines. Dans le cadre d'une étude sur la perception des risques associés à la pratique du vélo en ville, 50 personnes utilisant habituellement l'automobile pour se rendre au travail sont recrutées. L'expérimentation pourrait consister à leur donner une formation sur la pratique du vélo en ville et à les accompagner quelques jours durant leurs déplacements domicile-travail. Nous évaluerons la différence de leurs perceptions des risques associés à la pratique du vélo sur une échelle de 0 à 100 avant et après l'expérimentation. Nous pourrions supposer que la moyenne des différences est significativement négative, ce qui indiquerait que la perception du risque a diminué après l'expérimentation; autrement dit, la perception du risque serait plus faible en fin de période. \n:::\n:::\n\n\n\n### Test *t* et ses différentes variantes {#sec-0611}\n\nLe **t de Student**, appelé aussi **test _t_** (*t-test* en anglais), est un test paramétrique permettant de comparer les moyennes de deux groupes (échantillons), qui peuvent être indépendantes ou non :\n\n* **Échantillons indépendants (dits non appariés)** : les observations de deux groupes qui n'ont aucun lien entre eux. Par exemple, nous souhaitons vérifier si les moyennes du sentiment de sécurité des hommes et des femmes, ou encore si, les moyennes des loyers entre deux villes sont statistiquement différentes. Ainsi, les tailles des deux échantillons peuvent être différentes ($n_a \\neq n_b$).\n\n* **Échantillons dépendants (dits appariés)** : les individus des deux groupes sont les mêmes et sont donc associés par paires. Autrement dit, nous avons deux séries de valeurs de taille identique $n_a = n_b$ et $n_{ai}$ est le même individu que $n_{bi}$. Ce type d'analyse est souvent utilisée en études cliniques : pour $n$ individus, nous disposons d'une mesure quantitative de leur état de santé pour deux séries (l'une avant le traitement, l'autre une fois le traitement terminé). Cela permet de comparer les mêmes individus avant et après un traitement; nous parlons alors d'étude, d'expérience ou d'analyse pré-post. Concrètement, nous cherchons à savoir si la moyenne des différences des observations avant et après est significativement différente de 0. Si c'est le cas, nous pouvons conclure que l'expérimentation a eu un impact sur le phénomène mesuré (variable continue). Ce type d'analyse pré-post peut aussi être utilisé pour évaluer l'impact du réaménagement d'un espace public (rue commerciale, place publique, parc, etc.). Par exemple, nous pourrions questionner le même échantillon de commerçant(e)s ou personnes l'utilisant avant et après le réaménagement d'une artère commerciale.\n\n**Condition d'application**. Pour utiliser les tests de Student et de Welch, la variable continue doit être normalement distribuée. Si elle est fortement anormale, nous utiliserons le test non paramétrique de Wilcoxon ([section @sec-0612]). Il existe trois principaux tests pour comparer les moyennes de deux groupes :\n\n* Test de Student (test *t*) avec échantillons indépendants et variances similaires (méthode *pooled*).  Les variances de deux groupes sont semblables quand leur ratio varie de 0,5 à 2, soit $\\mbox{0,5}< (S^2_{X_A}/S^2_{X_B})<\\mbox{2}$.\n\n* Test de Welch (appelé aussi Satterthwaite) avec échantillons indépendants quand les variances des deux groupes sont dissemblables.\n\n* Test de Student (test *t*) avec échantillons dépendants.\n\nIl s'agit de vérifier si les moyennes des deux groupes sont statistiquement différentes avec les étapes suivantes :\n\n* Nous posons l'hypothèse nulle (*H~0~*), soit que les moyennes des deux groupes *A* et *B* ne sont pas différentes ($\\bar{X}_{A}=\\bar{X}_{B}$) ou, autrement dit, la différence des deux moyennes est nulle ($\\bar{X}_{A}-\\bar{X}_{B}=0$). L'hypothèse alternative (*H~1~*) est donc $\\bar{X}_{A}\\ne\\bar{X}_{B}$.\n\n* Nous calculons la valeur de *t* et le nombre de degrés de liberté. La valeur de *t* est négative quand la moyenne du groupe A est inférieure au groupe B et inversement.\n\n* Nous comparons la valeur absolue de *t* ($\\mbox{|t|}$) avec celle issue de la table des valeurs critiques de T ([section @sec-132]) avec le bon nombre de degrés de liberté et en choisissant un degré de signification (habituellement, *p* = 0,05). Si $\\mbox{|t|}$ est supérieure à la valeur *t* critique, alors les moyennes sont statistiquement différentes au degré de signification retenu.\n\n* Si les moyennes sont statistiquement différentes, nous pouvons calculer la taille de l'effet.\n\n\n**Cas 1. Test de Student pour des échantillons indépendants avec des variances similaires (méthode *pooled*).** La valeur de *t* est le ratio entre la différence des moyennes des deux groupes (numérateur) et l'erreur type groupée des deux échantillons (dénominateur) :\n\n$$\nt = \\frac{\\bar{X}_{A}-\\bar{X}_{B}}{\\sqrt{\\frac{S^2_p}{n_A}+\\frac{S^2_p}{n_B}}}\\mbox{ avec } S^2_p = \\frac{(n_A-1)S^2_{X_A}+(n_B-1)S^2_{X_B}}{n_A+n_B-2}\n$$ {#eq-cas1pooled}\n\n\navec $n_A$,$n_B$, $S^2_{X_A}$ et $S^2_{X_B}$ étant respectivement les nombres d'observations et les variances pour les groupes *A* et *B*, $S^2_p$ étant la variance groupée des deux échantillons et $n_A+n_B-2$ étant le nombre de degrés de liberté.\n\n**Cas 2. Test de Welch pour des échantillons indépendants (avec variances dissemblables).** Le test de Welch est très similaire au test de Student; seul le calcul de la valeur de _t_ est différent, pour tenir compte des variances respectives des groupes :\n\n$$\nt = \\frac{\\bar{X}_{A}-\\bar{X}_{B}}{\\sqrt{\\frac{S^2_{X_A}}{n_A}+\\frac{S^2_{X_B}}{n_B}}} \\mbox{ et } dl = \\frac{ \\left( \\frac{S^2_{X_A}}{n_A}+\\frac{S^2_{X_B}}{n_B} \\right)^2} {\\frac{S^4_{X_A}}{n^2_A(n_A-1)}+\\frac{S^4_{X_B}}{n^2_B(n_B-1)}}\n$$ {#eq-cas2welch}\n\nDans la syntaxe ci-dessous, nous avons écrit une fonction dénommée `test_independants` permettant de calculer les deux tests pour des échantillons indépendants. Dans cette fonction, vous pouvez repérer comment sont calculés les moyennes, les nombres d'observations et les variances pour les deux groupes, le nombre de degrés de liberté et les valeurs de *t* et de *p* pour les deux tests. Puis, nous avons créé aléatoirement deux jeux de données relativement à la vitesse de déplacement de cyclistes utilisant un vélo personnel ou un vélo en libre-service (généralement plus lourd) :\n\n* Au cas 1, 60 cyclistes utilisant un vélo personnel roulant en moyenne à 18 km/h (écart-type de 1,5) et 50 autres utilisant un système de vélopartage avec une vitesse moyenne de 15 km/h (écart-type de 1,5).\n\n* Au cas 2, 60 cyclistes utilisant un vélo personnel roulant en moyenne à 16 km/h (écart-type de 3) et 50 autres utilisant un système de vélopartage avec une vitesse moyenne de 15 km/h (écart-type de 1,5). Ce faible écart des moyennes, combiné à une plus forte variance réduit la significativité de la différence entre les deux groupes.\n\nD'emblée, l'analyse visuelle des boîtes à moustaches (@fig-ttest1) signale qu'au cas 1, contrairement au cas 2, les groupes sont plus homogènes (boîtes plus compactes) et les moyennes semblent différentes (les boîtes sont centrées différemment sur l'axe des ordonnées). Cela est confirmé par les résultats des tests.\n\n```{r}\n#| label: fig-ttest1\n#| echo: true\n#| message: false\n#| warning: false\n#| fig-align: center\n#| fig-cap: Boîtes à moustaches sur des échantillons fictifs non appariés\n#| out-width: \"75%\"\nlibrary(\"ggplot2\")\nlibrary(\"ggpubr\")\n# fonction ------------------\ntstudent_independants <- function(A, B){\n    x_a <- mean(A)           # Moyenne du groupe A\n    x_b <- mean(B)           # Moyenne du groupe B\n    var_a <- var(A)          # Variance du groupe A\n    var_b <- var(B)          # Variance du groupe B\n    sd_a <- sqrt(var_a)      # Écart-type du groupe A\n    sd_b <- sqrt(var_b)      # Écart-type du groupe B\n    ratio_v <- var_a / var_b # ratio des variances\n    n_a <- length(A)         # nombre d'observation du groupe A\n    n_b <- length(B)         # nombre d'observation du groupe B\n    \n    # T-test (variances égales)\n    dl_test <- n_a+n_b-2       # degrés de liberté\n    PooledVar <- (((n_a-1)*var_a)+((n_b-1)*var_b))/dl_test\n    t_test <- (x_a-x_b) / sqrt(((PooledVar/n_a)+(PooledVar/n_b)))\n    p_test <-  2*(1-(pt(abs(t_test), dl_test)))     \n    # Test Welch-Sattherwaite (variances inégales)\n    t_welch <- (x_a-x_b) / sqrt( (var_a/n_a) + (var_b/n_b))\n    dl_num = ((var_a/n_a) + (var_b/n_b))^2\n    dl_dem = ((var_a/n_a)^2/(n_a-1))  + ((var_b/n_b)^2/(n_b-1))\n    dl_welch = dl_num / dl_dem # degrés de liberté\n    p_welch <- 2*(1-(pt(abs(t_welch), dl_welch)))     \n    \n    cat(\"\\n groupe A (n = \", n_a,\"), moy = \", round(x_a,1),\", \n           variance = \", round(var_a,1),\", écart-type = \", round(sd_a,1),\n        \"\\n groupe B (n = \", n_b,\"), moy = \", round(x_b,1),\", \n          variance = \", round(var_b,1),\", écart-type = \", round(sd_b,1),\n        \"\\n ratio variance = \", round(ratio_v,2),\n        \"\\n t-test (variances égales): t(dl = \", dl_test, \") = \", round(t_test,4),\n         \", p = \", round(p_test,6),\n         \"\\n t-Welch (variances inégales): t(dl = \", round(dl_welch,3), \") = \",\n        round(t_welch,4), \", p = \", round(p_welch,6),  sep = \"\")    \n  \n    if (ratio_v > 0.5 && ratio_v < 2)  {\n      cat(\"\\n Variances semblables. Utilisez le test de Student!\")\n      p <- p_test\n    } else {\n      cat(\"\\n Variances dissemblables. Utilisez le test de Welch-Satterwaithe!\")\n      p <- p_welch\n    }\n    \n    if (p <=.05){\n      cat(\"\\n Les moyennes des deux groupes sont significativement différentes.\")\n    } else {\n      cat(\"\\n Les moyennes des deux groupes ne sont pas significativement différentes.\")\n    }\n}\n# CAS 1 : données fictives ------------------\n# Création du groupe A : 60 observations avec une vitesse moyenne de 18 et un écart-type de 1,5\nVelo1A <- rnorm(60,18,1.5)\n# Création du groupe B : 50 observations avec une vitesse moyenne de 15 et un écart-type de 1,5\nVelo1B <- rnorm(50,15,1.5)\ndf1 <- data.frame(\n  vitesse = c(Velo1A,Velo1B), \n  type = c(rep(\"Vélo personnel\", length(Velo1A)), rep(\"Vélopartage\", length(Velo1B)))\n)\nboxplot1 <- ggplot(data = df1, mapping=aes(x = type, y = vitesse, colour = type)) +\n  geom_boxplot(width=0.2)+\n  ggtitle(\"Données fictives (cas 1)\")+\n  xlab(\"Type de vélo\")+\n  ylab(\"Vitesse de déplacement (km/h)\")+\n  theme(legend.position = \"none\")\n# CAS 2 : données fictives ------------------\n# Création du groupe A : 60 observations avec une vitesse moyenne de 18 et un écart-type de 3\nVelo2A <- rnorm(60,16,3)\n# Création du groupe B : 50 observations avec une vitesse moyenne de 15 et un écart-type de 1,5\nVelo2B <- rnorm(50,15,1.5)\ndf2 <- data.frame(\n  vitesse = c(Velo2A,Velo2B), \n  type = c(rep(\"Vélo personnel\", length(Velo2A)), rep(\"Vélopartage\", length(Velo2B)))\n)\nboxplot2 <- ggplot(data = df2, mapping=aes(x = type, y = vitesse, colour = type)) +\n  geom_boxplot(width=0.2)+\n  ggtitle(\"Données fictives (cas 2)\")+\n  xlab(\"Type de vélo\")+\n  ylab(\"Vitesse de déplacement (km/h)\")+\n  theme(legend.position = \"none\")\nggarrange(boxplot1, boxplot2, ncol = 2, nrow = 1)\n# Appel de la fonction pour le cas 1\ntstudent_independants(Velo1A, Velo1B)\n# Appel de la fonction pour le cas 2\ntstudent_independants(Velo2A, Velo2B)\n```\n\n\n#### Principe de base et formulation pour des échantillons dépendants (appariés) {#sec-06111}\n\nNous disposons de plusieurs personnes pour lesquelles nous avons mesuré un phénomène (variable continue) à deux temps différents : généralement avant et après une expérimentation (analyse pré-post). Il s'agit de vérifier si la moyenne des différences des observations avant et après la période est différente de 0. Pour ce faire, nous réalisons les étapes suivantes :\n\n* Nous posons l'hypothèse nulle (*H~0~*), soit que la moyenne des différences entre les deux séries est égale à 0 ($\\bar{D} = 0$ avec $d = {x}_{t_1}- {x}_{t_2}$). L'hypothèse alternative (*H~1~*) est donc $\\bar{D} \\ne 0$. Notez que nous pouvons tester une autre valeur que 0.\n\n* Nous calculons la valeur de *t* et le nombre de degrés de liberté. La valeur de *t* est négative quand la moyenne des différences entre ${X}_{t_1}$ et ${X}_{t_2}$ est négative et inversement.\n\n* Nous comparons la valeur absolue de *t* ($\\mbox{|t|}$) avec celle issue de la table des valeurs critiques de T avec le nombre de degrés de liberté et en choisissant un degré de signification (habituellement, *p* = 0,05). Si $\\mbox{|t|}$ est supérieure à la valeur *t* critique, alors les moyennes sont statistiquement différentes au degré de signification retenu.\n\nPour le test de Student avec des échantillons appariés, la valeur de *t* se calcule comme suit :\n\n$$\nt = \\frac{\\bar{D}-\\mu_0}{\\sigma_D / \\sqrt{n}}\n$$ {#eq-ttestapparie}\n\n\navec $\\bar{D}$ étant la moyenne des différences entre les observations appariées de la série A et de la série B, $\\sigma_D$ l'écart des différences, *n* le nombre d'observations, et finalement $\\mu_0$ la valeur de l'hypothèse nulle que nous voulons tester (habituellement 0). Bien entendu, il est possible de fixer une autre valeur pour $\\mu_0$ : par exemple, avec $\\mu_0 = 10$, nous chercherions ainsi à vérifier si la moyenne des différences est significativement différente de 10. Le nombre de degrés de liberté est égal à $n-1$.\n\nDans la syntaxe ci-dessous, nous avons écrit une fonction dénommée `tstudent_dependants` permettant de réaliser le test de Student pour des échantillons appariés. Dans cette fonction, vous pouvez repérer comment sont calculés la différence entre les observations pairées, la moyenne et l'écart-type de cette différence, puis le nombre de degrés de liberté, les valeurs de *t* et de *p* pour les deux tests.\n\nPour illustrer l'utilisation de la fonction, nous avons créé aléatoirement deux jeux de données. Imaginons que ces données décrivent 50 personnes utilisant habituellement l'automobile pour se rendre au travail. Pour ces personnes, nous avons généré des valeurs du risque perçu de l'utilisation du vélo (de 0 à 100), et ce, avant et après une période de 20 jours ouvrables durant lesquels elles devaient impérativement se rendre au travail à vélo.\n\n* Au cas 1, les valeurs de risque ont une moyenne de 70 avant l'expérimentation et de 50 après l'expérimentation, avec des écarts-types de 5.\n\n* Au cas 2, les valeurs de risque ont une moyenne de 70 avant et de 66 après, avec des écarts-types de 5.\n\nD'emblée, l'analyse visuelle des boîtes à moustaches (@fig-ttest2) pairées montre que la perception du risque semble avoir nettement diminué après l'expérimentation pour le cas 1, mais pas pour le cas 2. Cela est confirmé par les résultats des tests.\n\n\n```{r}\n#| label: fig-ttest2\n#| echo: true\n#| message: false\n#| warning: false\n#| fig-align: center\n#| fig-cap: Boites à moustaches sur des échantillons fictifs appariés\n#| out-width: \"75%\"\nlibrary(\"ggplot2\")\nlibrary(\"ggpubr\")\ntstudent_dependants <- function(A, B, mu = 0){\n  d <- A-B           # différences entre les observations pairées\n  moy <- mean(d)     # Moyenne des différences\n  e_t <- sd(d)       # Écart-type des différences\n  n   <- length(A)   # nombre d'observations\n  dl  <- n-1         # nombre de degrés de liberté (variances égales)\n  \n  t <- (moy- mu) / (e_t/sqrt(n)) # valeur de t\n  p <-  2*(1-(pt(abs(t), dl)))\n  \n  cat(\"\\n groupe A : moy = \", round(mean(A),1),\", var = \", \n         round(var(A),1),\", sd = \", round(sqrt(var(A)),1),\n      \"\\n groupe B : moy = \", round(mean(B),1),\", var = \", \n         round(var(B),1),\", sd = \", round(sqrt(var(B)),1),\n      \"\\n Moyenne des différences = \", round(mean(moy),1),\n      \"\\n Ecart-type des différences = \", round(mean(e_t),1),\n      \"\\n t(dl = \", dl, \") = \", round(t,2),\n      \", p = \", round(p,3),  sep = \"\")\n  \n  if (p <=.05){\n    cat(\"\\n La moyenne des différences entre les échantillons est significative\")\n  }\n  else{\n    cat(\"\\n La moyenne des différences entre les échantillons n'est pas significative\")\n  }\n}\n# CAS 1 : données fictives ------------------\nAvant1 <- rnorm(50,70,5)\nApres1 <- rnorm(50,50,5)\ndf1 <- data.frame(Avant=Avant1, Apres=Apres1)\nboxplot1 <- ggpaired(df1, cond1 = \"Avant\", cond2 = \"Apres\", fill = \"condition\", \n                     palette = \"jco\", \n                     xlab = \"\", ylab = \"Sentiment de sécurité\", \n                     title = \"Données fictives (cas 1)\")\n# CAS 2 : données fictives ------------------\nAvant2 <- rnorm(50,70,5)\nApres2 <- rnorm(50,66,5)\ndf2 <- data.frame(Avant=Avant2, Apres=Apres2)\nboxplot2 <- ggpaired(df2, cond1 = \"Avant\", cond2 = \"Apres\", fill = \"condition\",\n                     palette = \"jco\", \n                     xlab = \"\", ylab = \"Sentiment de sécurité\", \n                     title = \"Données fictives (cas 2)\")\nggarrange(boxplot1, boxplot2, ncol = 2, nrow = 1)\n# Test t : appel de la fonction tstudent_dependants\ntstudent_dependants(Avant1, Apres1, mu = 0)\ntstudent_dependants(Avant2, Apres2, mu = 0)\n```\n\n\n#### Mesure de la taille de l'effet {#sec-06112}\n\nLa taille de l'effet permet d'évaluer la magnitude (force) de l'effet d'une variable (ici la variable qualitative à deux modalités) sur une autre (ici la variable continue). Dans le cas d'une comparaison de moyennes (avec des échantillons pairés ou non), pour mesurer la taille de l'effet, nous utilisons habituellement le *d* de Cohen ou encore le *g* de Hedges; le second étant un ajustement du premier. Notez que nous analysons la taille de l'effet uniquement si le test de Student ou de Welch s'est révélé significatif (p < 0,05).\n\n**Pourquoi utiliser le *d* de Cohen?** Deux propriétés en font une mesure particulièrement intéressante. Premièrement, elle est facile à calculer puisque *d* est le ratio entre la différence de deux moyennes de groupes (A, B) et l'écart-type combiné des deux groupes. Deuxièmement, *d* représente ainsi une mesure standardisée de la taille de l'effet; elle permet ainsi l'évaluation de la taille de l'effet indépendamment de l'unité de mesure de la variable continue. Concrètement, cela signifie que, quelle que soit l'unité de mesure de la variable continue *X*, *d* est toujours exprimée en unité d'écart-type de *X*. Cette propriété facilite ainsi grandement les comparaisons entre des valeurs de *d* calculées sur différentes combinaisons de variables (au même titre que le coefficient de variation ou le coefficient de corrélation, par exemple). Pour des échantillons indépendants de tailles différentes, le *d* de Cohen s'écrit : \n\n\n$$\n\\frac{\\bar{X}_{A}-\\bar{X}_{B}}{\\sqrt{\\frac{(n_A-1)S^2_A+(n_B-1)S^2_B}{n_A+n_B-2}}}\n$$ {#eq-dcohen}\n\navec $n_A$, $n_B$, $S^2_{X_A}$ et $S^2_{X_B}$ étant respectivement les nombres d'observations et les variances pour les groupes *A* et *B*, $S^2_p$.\n\nSi les échantillons sont de tailles identiques ($n_A=n_B$), alors *d* s'écrit :\n\n\n$$\nd = \\frac{\\bar{X}_{A}-\\bar{X}_{B}}{\\sqrt{(S^2_A+\\S^2_B)/2}} = \\frac{\\bar{X}_{A}-\\bar{X}_{B}}{(\\sigma_A+\\sigma_B)/2}\n$$ {#eq-dcohen2}\n\n\navec $\\sigma_A$ et $\\sigma_B$ étant les écarts-types des deux groupes (rappel : l'écart-type est la racine carrée de la variance).\n\nLe *g* de Hedge est simplement une correction de *d*, particulièrement importante quand les échantillons sont de taille réduite.\n\n$$\ng = d- \\left(1- \\frac{3}{4(n_A+n_B)-9} \\right)\n$$ {#eq-ghedge}\n\n\nMoins utilisé en sciences sociales, mais surtout en études cliniques, le delta de Glass est simplement la différence des moyennes des deux groupes indépendants (numérateur) sur l'écart-type du deuxième groupe (dénominateur). Dans une étude clinique, nous avons habituellement un groupe qui subit un traitement (groupe de traitement) et un groupe qui reçoit un placebo (groupe de contrôle ou groupe témoin). L'effet de taille est ainsi évalué par rapport au groupe de contrôle : \n\n$$\n\\Delta = \\frac{\\bar{X}_{A}-\\bar{X}_{B}}{\\sigma_B}\n$$ {#eq-dDelta}\n\nFinalement, pour des échantillons dépendants (pairés), le delta de Glass s'écrit : $d = \\bar{D}/{\\sigma_D}$ avec $\\bar{D}$ et $\\sigma_D$ étant la moyenne et l'écart-type des différences entre les observations.\n\n**Comment interpréter le *d* de Cohen?** Un effet est considéré comme faible avec $\\lvert d \\rvert$ à 0,2, modéré à 0,50 et fort à 0,80 [@cohen1992]. Notez que ces seuils ne sont que des conventions pour vous guider à interpréter la mesure de Cohen. D'ailleurs, dans son livre intitulé *Statistical power analysis for the behavioral sciences*, il écrit : « all conventions are arbitrary. One can only demand of them that they not be unreasonable » [@cohen2013]. Plus récemment, Sawilowsky [-@sawilowsky2009] a ajouté d'autres seuils à ceux proposés par Cohen (@tbl-convcohen).\n\n```{r}\n#| label: tbl-convcohen\n#| tbl-cap: Conventions pour l’interprétation du *d* de Cohen\n#| echo: false\n#| message: false\n#| warning: false\ndf <- data.frame(\n        Sawilowsky = c(\"0,1 : Très faible\", \"0,2 : Faible\", \"0,5 : Moyen\" , \"0,8 : Fort\", \"1,2 : Très fort\", \"2,0 : Énorme\"), \n        Cohen = c(\"\", \"0,2 : Faible\", \"0,5 : Moyen\" , \"0,8 : Fort\", \"\", \"\"))\n\nknitr::kable(df,\n           position = 'HOLD_position',\n           align= c(\"l\", \"l\")\n           )\n```\n\n\n#### Mise en œuvre dans R {#sec-06113}\n\nNous avons écrit précédemment les fonctions `tstudent_independants` et `tstudent_dependants` uniquement pour décomposer les différentes étapes de calcul des tests de Student et de Welch. Heureusement, il existe des fonctions de base (`t.test` et `var.test`) qui permettent de réaliser l'un ou l'autre de ces deux tests avec une seule ligne de code.\n\nLa fonction `t.test` permet ainsi de calculer les tests de Student et de Welch :\n\n* `t.test(x ~ y, data=, mu = 0, paired = FALSE, var.equal = FALSE,  conf.level = 0.95)` ou `t.test(x =, y =, mu = 0, paired = FALSE, var.equal = FALSE,  conf.level = 0.95)`. \n\n* Le paramètre `paired` est utilisé pour spécifier si les échantillons sont dépendants (`paired = TRUE`) ou indépendants (`paired = FALSE`).\n\n* Le paramètre `var.equal` est utilisé pour spécifier si les variances sont égales pour le test de Student (`var.equal = TRUE`) ou dissemblables pour le test de Welch (`var.equal = FALSE`).\n\n* `var.test(x, y)` ou `var.test(x ~ y, data=)` pour vérifier au préalable si les variances sont égales ou non et choisir ainsi un *t* de Student ou un *t* de Welch.\n\nLes fonctions `cohens_d` et `hedges_g` du *package* `effectsize` renvoient respectivement les mesures de *d* de Cohen et du *g* de Hedge :\n\n* `cohens_d(x ~ y, data = DataFrame, paired = FALSE, pooled_sd = TRUE)` ou  `cohens_d(x, y, data = DataFrame, paired = FALSE, pooled_sd = TRUE)`\n\n* `hedges_g(x ~ y, data = DataFrame, paired = FALSE, pooled_sd = TRUE)` ou `hedges_g(x, y, data = DataFrame, paired = FALSE, pooled_sd = TRUE)`\n\n* `glass_delta(x ~ y, data = DataFrame, paired = FALSE, pooled_sd = TRUE)` ou `glass_delta(x, y, data = DataFrame, paired = FALSE, pooled_sd = TRUE)`\n\n\nNotez que pour toutes ces fonctions, deux écritures sont possibles :\n\n* `x ~ y, data=` avec un `DataFrame` dans lequel `x` est une variable continue et `y` et un facteur binaire\n\n* `x, y` qui sont tous deux des vecteurs numériques (variable continue).\n\n**Exemple de test pour des échantillons indépendants**\n\nLa @fig-locataires représente la cartographie du pourcentage de locataires par secteur de recensement (SR) pour la région métropolitaine de recensement de Montréal (RMR) en 2016, soit une variable continue. L'objectif est de vérifier si la moyenne de ce pourcentage des SR de l'agglomération de Montréal est significativement différente de celles de SR hors de l'agglomération. \n\n\n![Pourcentage de locataires par secteur de recensement, région métropolitaine de recensement de Montréal, 2016](images/Chap06/FigureLocataires.jpg){#fig-locataires width=\"90%\" fig-align=\"center\"}\n\nLes résultats de la syntaxe  ci-dessous signalent que le pourcentage de locataires par SR est bien supérieur dans l'agglomération (moyenne = 59,7 %; écart-type = 21,4 %) qu'en dehors de l'agglomération de Montréal (moyenne = 27,3 %; écart-type = 20,1 %). Cette différence de 32,5 points de pourcentage est d'ailleurs significative et très forte (*t* = -23,95; *p* < 0,001, d de Cohen = 1,54).\n\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\n#| out-width: \"75%\"\n#| fig-align: center\n\nlibrary(\"foreign\")\nlibrary(\"effectsize\")\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\n# Importation du fichier\ndfRMR <- read.dbf(\"data/bivariee/SRRMRMTL2016.dbf\")\n# Définition d'un facteur binaire                  \ndfRMR$Montreal <- factor(dfRMR$Montreal, \n                           levels = c(0,1), \n                           labels = c(\"Hors de Montréal\" , \"Montréal\"))\n# Comparaison des moyennes ------------------------\n# Boites à moustaches (boxplot)\nggplot(data = dfRMR, mapping=aes(x = Montreal, y = Locataire, colour = Montreal)) +\n  geom_boxplot(width=0.2)+\n  theme(legend.position = \"none\")+\n  xlab(\"Zone\")+ ylab(\"Pourcentage de locataires\")+\n  ggtitle(\"Locataires par secteur de recensement\", \n          subtitle = \"région métropolitaine de recensement de Montréal, 2016\")\n# Nombre d'observations, moyennes et écarts-types pour les deux échantillons\ngroup_by(dfRMR, Montreal) %>%\n  summarise(\n    n = n(),\n    moy = mean(Locataire, na.rm = TRUE),\n    ecarttype = sd(Locataire, na.rm = TRUE)\n  )\n# Nous vérifions si les variances sont égales avec la fonction var.test\n# quand la valeur de P est inférieure à 0,05 alors les variances diffèrent\nv <- var.test(Locataire ~ Montreal, alternative = 'two.sided', conf.level = .95, data = dfRMR)\nprint(v)\n```\nLe test indique que nous n'avons aucune raison de rejeter l'hypothèse nulle selon laquelle les variances sont égales. Pour l'île de Montréal, l'écart-type est de 21,4; il est de 20,1 hors de l'île, soit une différence négligeable.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\n# Calcul du T de Student ou du T de Welch\np <- v$p.value\nif(p >= 0.05){\n  cat(\"\\n Les variances ne diffèrent pas!\",\n     \"\\n Nous utilisons le test de Student avec l'option var.equal = TRUE\", sep = \"\")\n    t.test(Locataire ~ Montreal,  # variable continue ~ facteur binaire \n           data = dfRMR,            # nom du DataFrame\n           conf.level = .95,       # intervalle de confiance pour la valeur de t\n           var.equal = TRUE)        # variances égales\n} else {\n  cat(\"\\n Les variances diffèrent!\",\n      \"\\n Nous utilisons le test de Welch avec l'option var.equal = FALSE\", sep = \"\")\n  t.test(Locataire ~ Montreal,   # variable continue ~ facteur binaire \n         data = dfRMR,           # nom du DataFrame\n         conf.level = .95,       # intervalle de confiance pour la valeur de t\n         var.equal = FALSE)        # variances différentes\n}\n# Effet de taille à analyser uniquement si le test est significatif\ncohens_d(Locataire ~ Montreal, data = dfRMR, paired = FALSE)\nhedges_g(Locataire ~ Montreal, data = dfRMR, paired = FALSE)\n```\nNotez que les valeurs du *d* de Cohen et du *g* de Hedge sont très semblables; rappelons que le second est une correction du premier pour des échantillons de taille réduite. Avec 951 observations, nous disposons d'un échantillon suffisamment grand pour que cette correction soit négligeable.\n\n**Exemple de syntaxe  pour un test de Student pour des échantillons dépendants**\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\n#| out-width: \"75%\"\n#| fig-align: center\n\nlibrary(\"ggpubr\")\nlibrary(\"dplyr\")\nPre <- c(79,71,81,83,77,74,76,74,79,70,66,85,69,69,82,\n         69,81,70,83,68,77,76,77,70,68,80,65,65,75,84)\nPost <- c(56,47,40,45,49,51,54,47,44,54,42,56,45,45,48,\n          55,59,58,56,41,56,51,45,55,49,49,48,43,60,50)\n# Première façon de faire un tableau : avec deux colonnes Avant et Après\ndf1 <- data.frame(Avant=Pre, Apres=Post)\nhead(df1)\nggpaired(df1, cond1 = \"Avant\", cond2 = \"Apres\", fill = \"condition\", palette = \"jco\",\n         xlab = \"\", ylab = \"Variable continue\")\n# Nombre d'observations, moyennes et écart-types\ncat(nrow(df1), \" observations\",\n    \"\\nPOST. moy = \", round(mean(df1$Avant),1), \", e.t. = \", round(sd(df1$Avant),1),\n    \"\\nPRE.  moy = \", round(mean(df1$Apres),1), \", e.t. = \", round(sd(df1$Apres),1), sep = \"\")\nt.test(Pre, Post, paired = TRUE)\n# Deuxième façon de faire un tableau : avec une colonne pour la variable continue\n# et une autre pour la variable qualitative\nn <- length(Pre)*2\ndf2 <- data.frame(\n       id=(1:n),\n       participant=(1:length(Pre)),\n       risque=c(Pre, Post)\n       )\ndf2$periode <- ifelse(df2$id <= length(Pre), \"Pré\", \"Post\")\nhead(df2)\n# nombre d'observations, moyennes et écarts-types pour les deux échantillons\ngroup_by(df2, periode) %>%\n  summarise(\n    n = n(),\n    moy = mean(risque, na.rm = TRUE),\n    et = sd(risque, na.rm = TRUE)\n    )\nggpaired(data = df2, x = \"periode\", y = \"risque\", fill = \"periode\",\n         xlab = \"\", ylab = \"Variable continue\")\nPre <- subset(df2, periode == \"Pré\")$risque\nPost <- subset(df2, periode == \"Post\")$risque\nt.test(Pre, Post, paired = TRUE)\n```\n\n#### Comparaison des moyennes pondérées {#sec-06114}\n\n\n::: bloc_objectif\n::: bloc_objectif-header\n::: bloc_objectif-icon\n:::\n**Moyennes pondérées**\n:::\n::: bloc_objectif-body\nEn études urbaines et en géographie, le recours aux données agrégées (non individuelles) est fréquent, par exemple au niveau des secteurs de recensement (comprenant généralement entre 2500 à 8000 habitants). Dans ce contexte, un secteur de recensement plus peuplé devrait avoir un poids plus important dans l'analyse. Il est possible d'utiliser les versions pondérées des tests présentés précédemment. Prenons deux exemples pour illustrer le tout :\n\n* Pour chaque secteur de recensement des îles de Montréal et de Laval, nous avons calculé la distance au parc le plus proche à travers le réseau de rues avec un système d'information géographique (SIG). Nous souhaitons vérifier si les personnes âgées de moins de 15 ans résidant sur l'île de Montréal bénéficient en moyenne d'une meilleure accessibilité au parc.\n\n* Dans une étude sur la concentration de polluants atmosphériques dans l'environnement autour des écoles primaires montréalaises, Carrier *et al.* [-@carrier2014] souhaitaient vérifier si les élèves fréquentant les écoles les plus défavorisées sont plus exposé(e)s au dioxyde d'azote (NO~2~) dans leur milieu scolaire. Pour ce faire, ils ont réalisé un test _t_ sur un tableau avec comme observations les écoles primaires et trois variables : la moyenne de NO~2~ (variable continue), les quintiles extrêmes d'un indice de défavorisation (premier et dernier quintiles, variable qualitative) et le nombre d'élèves par école (variable pour la pondération).\n\nPour réaliser un test *t* pondéré, nous pouvons utiliser la fonction `t_test` du package `sjstats`.\n:::\n:::\n\n\nEn guise d'exemple appliqué, dans la syntaxe  ci-dessous, nous avons refait le même test *t* que précédemment (`Locataire ~ Montreal`) en pondérant chaque secteur de recensement par le nombre de logements qu'il comprend.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"sjstats\")\nlibrary(\"dplyr\")\n# Calcul des statistiques pondérées\ngroup_by(dfRMR, Montreal) %>%\n  summarise(\n    n = sum(Logement),\n    MoyPond = weighted_mean(Locataire, Logement),\n    ecarttypePond = weighted_sd(Locataire, Logement)\n  )\n# Test t non pondéré\nt.test(Locataire ~ Montreal, dfRMR, \n       var.equal = TRUE, conf.level = .95)\n# Test t pondérée\nsjstats::t_test(dfRMR, \n                select  = \"Locataire\", \n                by = \"Montreal\", \n                weights = \"Logement\",\n                mu = 0,\n                paired = FALSE)\n```\n\n#### Comment rapporter un test de Student ou de Welch? {#sec-06115}\n\nPour les différentes versions du test, il est important de rapporter les valeurs de _t_ et de _p_, les moyennes et écarts-types des groupes. Voici quelques exemples.\n\n**Test de Student ou de Welch pour échantillons indépendants**\n\n* Dans la région métropolitaine de Montréal en 2005, le revenu total des femmes  (moyenne = 29 117 dollars; écart-type = 258 022) est bien inférieur à celui des hommes (moyenne = 44 463; écart-type = 588 081). La différence entre les moyennes des deux sexes (-15 345) en faveur des hommes est d’ailleurs significative (*t* = -27,09; *p* < 0,001).\n\n* Il y un effet significatif selon le sexe (*t* = -27,09; *p* < 0,001), le revenu total des hommes (moyenne = 44 463; écart-type = 588 081) étant bien supérieur à celui des femmes (moyenne = 29 117; écart-type = 258 022).\n\n* 50 personnes se rendent au travail à vélo (moyenne = 33,7; écart-type = 8,5) contre 60 en automobile (moyenne = 34; écart-type = 8,7). Il n'y a pas de différence significative entre les moyennes d'âge des deux groupes (*t*(108) = -0,79; *p* = 0,427).\n\n\n**Test de Student échantillons dépendants (pairés)**\n\n* Nous constatons une diminution significative de la perception du risque après l'activité (moyenne = 49,9; écart-type = 5,7) comparativement à avant (moyenne = 74,8; écart-type = 6,1), avec une différence de -24,8 (*t*(29) = -18,7; *p* < 0,001).\n\n* Les résultats du pré-test (moyenne = 49,9; écart-type = 5,7) et du post-test (moyenne = 74,8; écart-type = 6,1) montrent qu'il y une diminution significative de la perception du risque (*t*(29) = -18,7; *p* < 0,001).\n\nPour un texte en anglais, consultez\n[https://www.socscistatistics.com/tutorials/ttest/default.aspx](https://www.socscistatistics.com/tutorials/ttest/default.aspx){target=\"_blank\"}.\n\n\n### Test non paramétrique de Wilcoxon {#sec-0612}\n\n\n::: bloc_objectif\n::: bloc_objectif-header\n::: bloc_objectif-icon\n:::\n**Test non paramétrique de Wilcoxon**\n:::\n::: bloc_objectif-body\nSi la variable continue est fortement anormalement distribuée, il est déconseillé d'utiliser les tests de Student et de Welch. Nous privilégions le test des rangs signés de Wilcoxon (*Wilcoxon rank-sum test* en anglais). Attention, il est aussi appelé test U de Mann-Whitney. Ce test permet alors de vérifier si les deux groupes présentent des médianes différentes.\n\nPour ce faire, nous utilisons la fonction `wilcox.test` dans laquelle le paramètre `paired` permet de spécifier si les échantillons sont indépendants ou non (`FALSE` ou `TRUE`).\n:::\n:::\n\nDans l'exemple suivant, nous analysons le pourcentage de locataires dans les secteurs de recensement de la région métropolitaine de Montréal. Plus spécifiquement, nous comparons ce pourcentage entre les secteurs présents sur l'île et les secteurs hors de l'île. Il s'agit donc d'un test avec des échantillons indépendants.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"foreign\")\nlibrary(\"dplyr\")\n###############################\n# Échantillons indépendants\n###############################\ndfRMR <- read.dbf(\"data/bivariee/SRRMRMTL2016.dbf\")\n# Définition d'un facteur binaire                  \ndfRMR$Montreal <- factor(dfRMR$Montreal, \n                           levels =   c(0,1), \n                           labels = c(\"Hors de Montréal\" , \"Montréal\"))\n# Calcul du nombre d'observations, des moyennes et \n# des écarts-types des rangs pour les deux échantillons\ngroup_by(dfRMR, Montreal) %>%\n  summarise(\n    n = n(),\n    moy_rang = mean(rank(Locataire), na.rm = TRUE),\n    med_rang = median(rank(Locataire), na.rm = TRUE),\n    ecarttype_rang = sd(rank(Locataire), na.rm = TRUE)\n  )\n# Test des rangs signés de Wilcoxon sur des échantillons indépendants\nwilcox.test(Locataire ~ Montreal, dfRMR)\n```\n\nNous observons bien ici une différence significative entre le pourcentage de locataires des secteurs de recensement sur l'île (rang médian = 216) et ceux en dehors de l'île (rang médian = 261).\n\nPour le second exemple, nous générons deux jeux de données au hasard représentant une mesure d'une variable pré-traitement (*pre*) et post-traitement (*post*) pour un même échantillon.\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\n###############################\n# Échantillons dépendants\n###############################\npre <- sample(60:80, 50, replace = TRUE)\npost <- sample(30:65, 50, replace = TRUE)\ndf1 <- data.frame(Avant=pre, Apres=post)\n# Nombre d'observations, moyennes et écart-types\ncat(nrow(df1), \" observations\",\n    \"\\nPOST. median = \", round(median(df1$Avant), 1), \n             \", moy = \", round(mean(df1$Avant), 1),\n    \"\\nPRE.  median = \", round(median(df1$Apres), 1), \n             \", moy = \", round(mean(df1$Apres), 1), sep = \"\")\nwilcox.test(df1$Avant, df1$Apres, paired = TRUE)\n```\n\nÀ nouveau, nous obtenons une différence significative entre les deux variables.\n\n**Comment rapporter un test de Wilcoxon?**\n\nLorsque nous rapportons les résultats d'un test de Wilcoxon, il est important de signaler la valeur du test (*W*), le degré de signification (valeur de *p*) et éventuellement la médiane des rangs ou de la variable originale pour les deux groupes. Voici quelques exemples :\n\n* Les résultats du test des rangs signés de Wilcoxon signalent que les rangs de l'île de Montréal sont significativement plus élevés que ceux de l'île de Laval (*W* = 1223, *p* < 0,001).\n\n* Les résultats du test de Wilcoxon signalent que les rangs post-tests sont significativement plus faibles que ceux du pré-test (*W* = 1273,5, *p* < 0,001).\n\n* Les résultats du test de Wilcoxon signalent que la médiane des rangs pré-tests (médiane = 69) est significativement plus forte que celle du post-test (médiane = 50,5) (*W* = 1273,5, *p* < 0,001).\n\n\n## Relation entre une variable quantitative et une variable qualitative à plus de deux modalités {#sec-062}\n\n::: bloc_objectif\n::: bloc_objectif-header\n::: bloc_objectif-icon\n:::\n**Existe-t-il une relation entre une variable continue et une variable qualitative comprenant plus de deux modalités?**\n:::\n::: bloc_objectif-body\nPour répondre à cette question, nous avons recours à deux méthodes : l’analyse de variance – **ANOVA**, _**AN**alysis **O**f **VA**riance_ en anglais – et le test non paramétrique de Kruskal-Wallis. La première permet de vérifier si les moyennes de plusieurs groupes d'une population donnée sont ou non significativement différentes; la seconde, si leurs médianes sont différentes.\n:::\n:::\n\n\n### Analyse de variance {#sec-0621}\n\nL’analyse de variance (ANOVA) est largement utilisée en psychologie, en médecine et en pharmacologie. Prenons un exemple classique en pharmacologie pour tester l'efficacité d'un médicament. Quatre groupes de population sont constitués :\n\n* un premier groupe d'individus pour lequel nous administrons un placebo (un médicament sans substance active), soit le groupe de contrôle ou le groupe témoin;\n\n* un second groupe auquel nous administrons le médicament avec un faible dosage;\n\n* un troisième avec un dosage moyen;\n\n* un quatrième avec un dosage élevé.\n\nLa variable continue permet d'évaluer l'évolution de l'état de santé des individus (par exemple, la variation du taux de globules rouges dans le sang avant et après le traitement). Si le traitement est efficace, nous nous attendons alors à ce que les moyennes des deuxième, troisième et quatrième groupes soient plus élevées que celle du groupe de contrôle. Les différences de moyennes entre les second, troisième et quatrième groupes permettent aussi de repérer le dosage le plus efficace. Si nous n'observons aucune différence significative entre les groupes, cela signifie que l'effet du médicament ne diffère pas de l'effet d'un placébo.\n\nL'ANOVA est aussi très utilisée en études urbaines, principalement pour vérifier si un phénomène urbain varie selon plusieurs groupes d'une population donnée ou de régions géographiques. En guise d'exemple, le recours à l'ANOVA permet de répondre aux questions suivantes :\n\n* Les moyennes des niveaux d'exposition à un polluant atmosphérique (variable continue) varient-elles significativement selon le mode de transport utilisé (automobile, vélo, transport en commun) pour des trajets similaires en heures de pointe?\n\n* Pour une métropole donnée, les moyennes des loyers (variable continue) sont-elles différentes entre les logements de la ville centre versus ceux localisés dans la première couronne et ceux de la seconde couronne?\n\n\n#### Calcul des trois variances pour l'ANOVA {#sec-06211}\n\nL'ANOVA repose sur le calcul de trois variances :\n\n* **la variance totale** (*VT*) de la variable dépendante continue, soit la somme des carrés des écarts à la moyenne de l'ensemble de la population (@eq-anova1);\n\n* la **variance intergroupe** (*Var~inter~*) ou variance expliquée (*VE*), soit la somme des carrés des écarts entre la moyenne de chaque groupe et la moyenne de l’ensemble du jeu de données multipliées par le nombre d’individus appartenant à chacun des groupes (@eq-anova2);\n\n* la **variance intragroupe**  (*Var~intra~*) ou variance non expliquée (*VNE*), soit la somme des variances des groupes de la variable indépendante (@eq-anova3).\n\n$$\nVT=\\sum_{i=1}^n (y_{i}-\\overline{y})^2\n$$ {#eq-anova1}\n\n$$\nVar_{inter} \\mbox{ ou } VE=n_{g_1}\\sum_{i\\in{g_1}}(\\overline{y_{g_1}}-\\overline{y})^2 + n_{g_2}\\sum_{i\\in{g_2}}(\\overline{y_{g_2}}-\\overline{y})^2 + ... + n_{g_k}\\sum_{i\\in{g_n}}(\\overline{y_{g_k}}-\\overline{y})^2\n$$ {#eq-anova2}\n\n$$\nVar_{intra} \\mbox{ ou } VNE=\\sum_{i\\in{g_1}}(y_{i}-\\overline{y_{g_1}})^2 + \\sum_{i\\in{g_2}}(y_{i}-\\overline{y_{g_2}})^2 + ... + \\sum_{i\\in{g_n}}(y_{i}-\\overline{y_{g_k}})^2 \n$$ {#eq-anova3}\n\noù $\\overline{y}$ est la moyenne de l'ensemble de la population; $\\overline{y_{g_1}}$, $\\overline{y_{g_2}}$, $\\overline{y_{g_k}}$ sont respectivement les moyennes des groupes 1 à _k_ (_k_ étant le nombre de modalités de la variable qualitative) et $n_{g_1}$,$n_{g_2}$ et $n_{g_k}$ sont les nombres d'observations dans les groupes 1 à _k_.\n\nLa variance totale (*VT*) est égale à la somme de la variance intergroupe (expliquée) et la variance intragroupe (non expliquée) (@eq-anova5). Le ratio entre la variance intergroupe (expliquée) et la variance totale est dénommé *Eta^2^* (@eq-anova6). Il varie de 0 à 1 et exprime la proportion de la variance de la variable continue qui est expliquée par les différentes modalités de la variable qualitative.\n\n$$\nVT = Var_{inter} + Var_{intra} \\mbox{ ou } VT = VNE + VE\n$$ {#eq-anova5}\n\n$$\n\\eta^2= \\frac{Var_{inter}}{VT} \\mbox{ ou }  \\eta^2= \\frac{VE}{VT}\n$$ {#eq-anova6}\n\n\n::: bloc_astuce\n::: bloc_astuce-header\n::: bloc_astuce-icon\n:::\n**La décomposition de la variance totale : une notion fondamentale en statistique** \n:::\n::: bloc_astuce-body\nLa **variance totale** est égale à la somme des variances intragroupe et intergroupe. Nous verrons qu'elle est aussi utilisée pour évaluer la qualité d'une partition d'une population en plusieurs groupes dans le chapitre sur les méthodes de classification ([chapitre @sec-chap13]). En ANOVA, nous retenons que :\n\n* plus la variance intragroupe est faible, plus les différents groupes sont homogènes;\n\n* plus la variance intergroupe est forte, plus les moyennes des groupes sont différentes et donc plus les groupes sont dissemblables. \n\nAutrement dit, plus la variance intergroupe (**dissimilarité** des groupes) est maximisée et corollairement plus la variance intragroupe (**homogénéité** de chacun des groupes) est minimisée, plus les groupes sont clairement distincts et plus l'ANOVA est performante.\n:::\n:::\n\n\nExaminons un premier jeu de données fictives sur la vitesse de déplacement de cyclistes (variable continue exprimée en km/h) et une variable qualitative comprenant trois groupes de cyclistes utilisant soit un vélo personnel (*n~A~* = 5), soit en libre-service (*n~B~* = 7), soit électrique (*n~C~* = 6) (@tbl-aovfictive1). D'emblée, nous notons que les moyennes de vitesse des trois groupes sont différentes : 17,6 km/h pour les cyclistes avec leur vélo personnel, 12,3 km/h celles et ceux avec des vélos en libre-service et 23,1 km/h pour les cyclistes avec un vélo électrique. Pour chaque observation, la troisième colonne du tableau représente les écarts à la moyenne globale mis au carré, tandis que les colonnes suivantes représentent la déviation au carré de chaque observation à la moyenne de son groupe d'appartenance. Ainsi, pour la première observation, nous avons $(\\mbox{16,900} - \\mbox{17,339})^2 = \\mbox{0,193}$ et $(\\mbox{16,900} - \\mbox{17,580})^2~ = \\mbox{0,462}$. Les valeurs des trois variances sont les suivantes :\n\n* la **variance totale** (*VT*) est donc égale à la somme de la troisième colonne ($\\mbox{424,663}$).\n* la **variance intergroupe** (expliquée, *VE*), elle est égale à $\\mbox{5}\\times(\\mbox{17,580-17,339})^2+\\mbox{7}\\times(\\mbox{12,257-17,339})^2+\\mbox{6}\\times(\\mbox{23,067-17,339})^2 = \\mbox{377,904}$.\n* la **variance intragroupe** (non expliquée, *VNE*) est égale à $\\mbox{11,228+21,537+13,993=46,758}$. \n\nNous avons donc $VT = Var_{inter} + Var_{intra}$, soit $\\mbox{424,663 = 377,904 + 46,758}$ et $\\eta_2 = \\mbox{377,904 / 424,663 = 0,89}$. Cela signale que 89 % de la variance de la vitesse des cyclistes est expliquée par le type de vélo utilisé.\n\n```{r}\n#| label: tbl-aovfictive1\n#| tbl-cap: Données fictives et calcul des trois variances (cas 1)\n#| #| echo: false\n#| message: false\n#| warning: false\nVeloA <- c(16.9, 20.4, 16.1, 17.7, 16.8)\nVeloB <- c(13.4, 11.3, 14.0, 12.4, 13.7, 8.5, 12.5)\nVeloC <- c(22.9, 26.0, 23.6, 21.0, 22.3, 22.6)\nmoyA <- mean(VeloA)\nmoyB <- mean(VeloB)\nmoyC <- mean(VeloC)\ngrandmoy <- mean(c(VeloA,VeloB,VeloC))\nnA <- length(VeloA)\nnB <- length(VeloB)\nnC <- length(VeloC)\nn <- nA + nB + nC\nVT <- sum((c(VeloA,VeloB, VeloC)-grandmoy)^2)\nVNE_A <- sum((VeloA-moyA)^2)\nVNE_B <- sum((VeloB-moyB)^2)\nVNE_C <- sum((VeloC-moyC)^2)\nVNE <- VNE_A + VNE_B + VNE_C\nVE <- nA*(moyA-grandmoy)^2 + nB*(moyB-grandmoy)^2 + nC*(moyC-grandmoy)^2\nEta2 <- round(VE / VT, 4)\n  \ndf <- data.frame(\n  velo = c(rep(\"A. personnel\", length(VeloA)), \n           rep(\"B. libre-service\", length(VeloB)),\n           rep(\"C. électrique\", length(VeloC))),\n  kmh = c(VeloA,VeloB, VeloC))\ndf$VT <- (df$kmh - grandmoy)^2\ndf$VNE_A <- ifelse(df$velo == \"A. personnel\", (df$kmh - moyA)^2, NA)\ndf$VNE_B <- ifelse(df$velo == \"B. libre-service\", (df$kmh - moyB)^2, NA)\ndf$VNE_C <- ifelse(df$velo == \"C. électrique\", (df$kmh - moyC)^2, NA)\ndf_cas1 <- df\ntabl <- df\ntabl$velo <- as.character(tabl$velo)\ntabl[19,1] <- \"grande moyenne\"\ntabl[20,1] <- \"moyenne groupe A\"\ntabl[21,1] <- \"moyenne groupe B\"\ntabl[22,1] <- \"moyenne groupe C \"\ntabl[19,2] <- round(grandmoy,3)\ntabl[20,2] <- round(moyA,3)\ntabl[21,2] <- round(moyB,3)\ntabl[22,2] <- round(moyC,3)\ntabl[23,1] <- \"Variance totale\"\ntabl[24,1] <- \"Variance intragroupe\"\ntabl[23,3] <- sum(tabl$VT, na.rm = TRUE)\ntabl[24,4] <- sum(tabl$VNE_A, na.rm = TRUE)\ntabl[24,5] <- sum(tabl$VNE_B, na.rm = TRUE)\ntabl[24,6] <- sum(tabl$VNE_C, na.rm = TRUE)\ntabl$VT <- round(tabl$VT,3)\ntabl$VNE_A <- round(tabl$VNE_A,3)\ntabl$VNE_B <- round(tabl$VNE_B,3)\ntabl$VNE_C <- round(tabl$VNE_C,3)\nopts <- options(knitr.kable.NA = \"--\")\n\nknitr::kable(tabl, \n           caption = \"Données fictives et calcul des trois variances (cas 1)\",\n           format.args = list(decimal.mark = ',', big.mark = \" \"),\n             col.names = c(\"Type de vélo\",\n                \"km/h\",\n                \"$(y_{i}-\\\\overline{y})^2$\",\n                \"$(y_{i}-\\\\overline{y_{A}})^2$\",\n                \"$(y_{i}-\\\\overline{y_{B}})^2$\",\n                \"$(y_{i}-\\\\overline{y_{C}})^2$\"\n                ),\n                align= c(\"l\", \"c\", \"r\", \"r\", \"r\", \"r\")\n)\n```\n\nExaminons un deuxième jeu de données fictives pour lequel le type de vélo utilisé n'aurait que peu d'effet sur la vitesse des cyclistes (@tbl-aovfictive2). D'emblée, les moyennes des trois groupes semblent très similaires (19,3, 17,9 et 18,7). Les valeurs des trois variances sont les suivantes :\n\n* la **variance totale** (*VT*) est égale à $\\mbox{121,756}$.\n* la **variance intergroupe** (expliquée, *VE*) est égale à $\\mbox{5}\\times(\\mbox{19,300-18,528})^2+\\mbox{7}\\times(\\mbox{17,871-18,528})^2+\\mbox{6}\\times(\\mbox{18,650-18,528})^2 = \\mbox{6,087}$.\n* la **variance intragroupe** (non expliquée, *VNE*) est égale à $\\mbox{9,140+50,254+56,275 = 115,669}$.\n\nNous avons donc $VT = Var_{inter} + Var_{intra}$, soit $\\mbox{121,756 = 6,087 + 115,669}$ et $\\eta_2 = \\mbox{6,087 / 121,756 = 0,05}$. Cela signale que 5 % de la variance de la vitesse des cyclistes est uniquement expliquée par le type de vélo utilisé.\n\n```{r}\n#| label: tbl-aovfictive2\n#| tbl-cap: Données fictives et calcul des trois variances (cas 2)\n#| echo: false\n#| message: false\n#| warning: false\nVeloA <- c(17.5, 19.0, 19.7, 18.7, 21.6)\nVeloB <- c(13.7, 20.8, 15.1, 18.8, 21.5, 16.5, 18.7)\nVeloC <- c(16.6, 16.3, 15.6, 20.0, 24.6, 18.8)\nmoyA <- mean(VeloA)\nmoyB <- mean(VeloB)\nmoyC <- mean(VeloC)\ngrandmoy <- mean(c(VeloA,VeloB,VeloC))\nnA <- length(VeloA)\nnB <- length(VeloB)\nnC <- length(VeloC)\nn <- nA + nB + nC\nVT <- sum((c(VeloA,VeloB, VeloC)-grandmoy)^2)\nVNE_A <- sum((VeloA-moyA)^2)\nVNE_B <- sum((VeloB-moyB)^2)\nVNE_C <- sum((VeloC-moyC)^2)\nVNE <- VNE_A + VNE_B + VNE_C\nVE <- nA*(moyA-grandmoy)^2 + nB*(moyB-grandmoy)^2 + nC*(moyC-grandmoy)^2\nEta2 <- round(VE / VT, 4)\n  \ndf <- data.frame(\n  velo = c(rep(\"A. personnel\", length(VeloA)), \n           rep(\"B. libre-service\", length(VeloB)),\n           rep(\"C. électrique\", length(VeloC))),\n  kmh = c(VeloA,VeloB, VeloC))\ndf$VT <- (df$kmh - grandmoy)^2\ndf$VNE_A <- ifelse(df$velo == \"A. personnel\", (df$kmh - moyA)^2, NA)\ndf$VNE_B <- ifelse(df$velo == \"B. libre-service\", (df$kmh - moyB)^2, NA)\ndf$VNE_C <- ifelse(df$velo == \"C. électrique\", (df$kmh - moyC)^2, NA)\ndf_cas2 <- df\ntabl <- df\ntabl$velo <- as.character(tabl$velo)\ntabl[19,1] <- \"grande moyenne\"\ntabl[20,1] <- \"moyenne groupe A\"\ntabl[21,1] <- \"moyenne groupe B\"\ntabl[22,1] <- \"moyenne groupe C \"\ntabl[19,2] <- round(grandmoy,3)\ntabl[20,2] <- round(moyA,3)\ntabl[21,2] <- round(moyB,3)\ntabl[22,2] <- round(moyC,3)\ntabl[23,1] <- \"Variance totale\"\ntabl[24,1] <- \"Variance intragroupe\"\ntabl[23,3] <- sum(tabl$VT, na.rm = TRUE)\ntabl[24,4] <- sum(tabl$VNE_A, na.rm = TRUE)\ntabl[24,5] <- sum(tabl$VNE_B, na.rm = TRUE)\ntabl[24,6] <- sum(tabl$VNE_C, na.rm = TRUE)\ntabl$VT <- round(tabl$VT,3)\ntabl$VNE_A <- round(tabl$VNE_A,3)\ntabl$VNE_B <- round(tabl$VNE_B,3)\ntabl$VNE_C <- round(tabl$VNE_C,3)\nopts <- options(knitr.kable.NA = \"--\")\n\nknitr::kable(tabl, \n           format.args = list(decimal.mark = ',', big.mark = \" \"),\n            col.names = c(\"Type de vélo\",\n                \"km/h\",\n                \"$(y_{i}-\\\\overline{y})^2$\",\n                \"$(y_{i}-\\\\overline{y_{A}})^2$\",\n                \"$(y_{i}-\\\\overline{y_{B}})^2$\",\n                \"$(y_{i}-\\\\overline{y_{C}})^2$\"),\n            align= c(\"l\", \"c\", \"r\", \"r\", \"r\", \"r\")\n           )\n```\n\n\n#### Test de Fisher {#sec-06212}\n\nPour vérifier si les moyennes sont statistiquement différentes (autrement dit, si leur différence est significativement différente de 0), nous avons recours au test *F* de Fisher. Pour ce faire, nous posons l'hypothèse nulle (*H~0~*), soit que les moyennes des groupes sont égales; autrement dit que la variable qualitative n'a pas d'effet sur la variable continue (indépendance entre les deux variables). L'hypothèse alternative (*H~1~*) est donc que les moyennes sont différentes. Pour nos deux jeux de données fictives ci-dessus comprenant trois groupes, *H~0~* signifie que $\\overline{y_{A}}=\\overline{y_{B}}=\\overline{y_{C}}$. La statistique *F* se calcule comme suit :\n\n\n$$\nF = \\frac{\\frac{Var{inter}}{k-1}}{\\frac{Var{intra}}{n-k}}\\mbox{ ou } F = \\frac{\\frac{VE}{k-1}}{\\frac{VNE}{n-k}}\n$$ {#eq-anovaF}\n\noù $n$ et $k$ sont respectivement les nombres d'observations et de modalités de la variable qualitative. L'hypothèse nulle (les moyennes sont égales) est rejetée si la valeur du *F* calculé est supérieure à la valeur critique de la table *F* avec les degrés de liberté *(k-1, n-k)* et un seuil \n$\\alpha$ (*p*=0,05 habituellement) (voir la table des valeurs critiques de *F*, [section @sec-132]). Notez que nous utilisons rarement la table *F* puisqu'avec la fonction `aov`, nous obtenons directement la valeur *F* et celle de *p* qui lui est associée. Concrètement, si le test _F_ est significatif (avec *p* < 0,05), plus la valeur de *F* est élevée, plus la différence entre les moyennes est élevée.\n\nAppliquons rapidement la démarche du test *F* à nos deux jeux de données fictives qui comprennent 3 modalités pour la variable qualitative et 18 observations. Avec $\\alpha$ = 0,05, 2 degrés de liberté (3-1) au numérateur et 15 au dénominateur (18-3), la valeur critique de F est de 3,68. Nous en concluons alors que :\n\n* Pour le cas A, le *F* calculé est égal à $\\mbox{(377,904 / 2) / (46,758 / 15) = 60,62}$. Il est  supérieur à la valeur *F* critique; les moyennes sont donc statistiquement différentes au seuil 0,05. Autrement dit, nous aurions eu moins de 5 % de chance d'obtenir un échantillon produisant ces résultats si en réalité la différence entre les moyennes était de 0.\n\n* Pour le cas B, le *F* calculé est égal à $\\mbox{(6,087 / 2) / (115,669 / 15) = 0,39}$. Il est inférieur à la valeur *F* critique; les moyennes ne sont donc pas statistiquement différentes au seuil de 0,05.\n\n#### Conditions d'application de l'ANOVA et solutions de rechange {#sec-06213}\n\nTrois conditions d'application doivent être vérifiées avant d'effectuer une analyse de variance sur un jeu de données :\n\n* **Normalité des groupes.** Le test de Fisher repose sur le postulat que les échantillons (groupes) sont normalement distribués. Pour le vérifier, nous avons recours au test de normalité de Shapiro–Wilk ([section @sec-025413]). Rappelez-vous toutefois que ce test est très restrictif, surtout pour de grands échantillons.\n\n* **Homoscédasticité**. La variance dans les échantillons doit être la même (homogénéité des variances). Pour vérifier cette condition, nous utilisons les tests de Levene, de Bartlett ou de Breusch-Pagan.\n\n* **Indépendance des observations (pseudo-réplication).** Chaque individu doit appartenir à un et un seul groupe. En d'autres termes, les observations ne sont pas indépendantes si plusieurs mesures (variable continue) sont faites sur un même individu. Si c'est le cas, nous utiliserons alors une analyse de variance sur des mesures répétées (voir le bloc à la fin du chapitre).\n\n**Quelles sont les conséquences si les conditions d'application ne sont pas respectées?** La non-vérification des conditions d'application cause deux problèmes distincts : elle affecte la puissance du test (sa capacité à détecter un effet, si celui-ci existe réellement) et le taux d'erreur de type 1 (la probabilité de trouver un résultat significatif alors qu'aucune relation n'existe réellement, soit un faux positif) [@glass1972consequences; @lix1996consequences].\n\n* Si la distribution est asymétrique plutôt que centrée (comme pour une distribution normale), la puissance et le taux d'erreur de type 1 sont tous les deux peu affectés, car le test est non orienté (la différence de moyennes peut être négative ou positive).\n\n* Si la distribution est leptocurtique (pointue, avec des extrémités de la distribution plus importantes), le taux d'erreur de type 1 est peu affecté; en revanche, la puissance du test est réduite. L'inverse s'observe si la distribution est platicurtique (aplatie, c'est-à-dire avec des extrémités de la distribution plus réduites.\n\n* Si les groupes ont des variances différentes, le taux d'erreur de type 1 augmente légèrement.\n\n* Si les observations ne sont pas indépendantes, à la fois le taux d'erreur de type 1 et la puissance du test sont fortement affectés.\n\n* Si les échantillons sont petits, les effets présentés ci-dessus sont démultipliés.\n\n* Si plusieurs conditions ne sont pas respectées, les conséquences présentées ci-dessus s'additionnent, voire se combinent.\n\n**Que faire quand les conditions d'application relatives à la normalité ou à l'homoscédasticité ne sont vraiment pas respectées?** Signalons d'emblée que le non-respect de ces conditions ne change rien à la décomposition de la variance (*VT = V~intra~+V~inter~*). Cela signifie que vous pouvez toujours calculer *Eta^2^*. Par contre, le test de Fisher ne peut pas être utilisé, car il est biaisé comme décrit précédemment. Quatre solutions sont envisageables :\n\n* Lorsque les échantillons sont fortement anormalement distribués, certains auteurs vont simplement transformer leur variable en appliquant une fonction logarithme (le plus souvent) ou racine carrée, inverse ou exponentielle, et reporter le test de Fisher calculé sur cette transformation. Attention toutefois! Transformer une variable ne va pas systématiquement la rapprocher d'une distribution normale et complique l'interprétation finale des résultats. Par conséquent, avant de recalculer votre test *F*, il convient de réaliser un test de normalité de Shapiro–Wilk et un test d'homoscédasticité (Levene, Bartlett ou Breusch-Pagan) sur la variable continue transformée.\n\n* Détecter les observations qui contribuent le plus à l'anormalité et à l'hétéroscédasticité (valeurs aberrantes ou extrêmes). Supprimez-les et refaites votre ANOVA en vous assurant que les conditions sont désormais respectées. Notez que supprimer des observations peut être une pratique éthiquement questionnable en statistique. Si vos échantillons sont bien constitués et que la mesure collectée n'est pas erronée, pourquoi donc la supprimer? Si vous optez pour cette solution, prenez soin de comparer les résultats avant et après la suppression des observations. Si les conditions sont respectées après la suppression et que les résultats de l'ANOVA (*Eta^2^* et test *F* de Fisher) sont très semblables, conservez donc les résultats de l'ANOVA initiale et signalez que vous avez procédé aux deux tests.\n\n* Lorsque les variances des groupes sont dissemblables, vous pouvez utiliser le test de Welch pour l'ANOVA au lieu du test *F* de Fisher. \n\n* Dernière solution, lorsque les deux conditions ne sont vraiment pas respectées, utilisez le test non paramétrique de Kruskal-Wallis. Par analogie au *t* de Student, il correspond au test des rangs signés de Wilcoxon. Ce test est décrit dans la section suivante.\n\nVous l'aurez compris, dans de nombreux cas en statistique, les choix méthodologiques dépendent en partie de la subjectivité des chercheur(se)s. Il faut s'adapter au jeu de données et à la culture statistique en vigueur dans votre champ d'études. N'hésitez pas à réaliser plusieurs tests différents pour évaluer la robustesse de vos conclusions et fiez-vous en premier lieu à ceux pour lesquels votre jeu de données est le plus adapté.\n\n### Test non paramétrique de Kruskal-Wallis {#sec-0622}\n\nLe test non paramétrique de Kruskal-Wallis est une solution de rechange à l'ANOVA classique lorsque le jeu de données présente de graves problèmes de normalité et d'hétéroscédasticité. Cette méthode représente une ANOVA appliquée à une variable continue transformée préalablement en rangs. Du fait de la transformation en rangs, nous ne vérifions plus si les moyennes sont différentes, mais bel et bien si les médianes de la variable continue sont différentes. Pour ce faire, nous utiliserons la fonction `kruskal.test`.\n\n### Mise en œuvre dans R {#sec-0623}\n\nDans une étude récente, Apparicio *et al.* [-@2018_1] ont comparé les expositions au bruit et à la pollution atmosphérique aux heures de pointe à Montréal en fonction du mode de transport utilisé. Pour ce faire, trois équipes de trois personnes ont été constituées : une personne à vélo, une autre en automobile et une dernière se déplaçant en transport en commun, équipées de capteurs de pollution, de sonomètres, de vêtements biométriques et d’une montre GPS. Chaque matin, à huit heures précises, les membres de chaque équipe ont réalisé un trajet d'un quartier périphérique de Montréal vers un pôle d'enseignement (université) ou d'emploi localisé au centre-ville. Le trajet inverse était réalisé le soir à 17 h. Au total, une centaine de trajets ont ainsi été réalisés. Des analyses de variance ont ainsi permis de comparer les trois modes (automobile, vélo et transport en commun) en fonction des temps de déplacement, des niveaux d'exposition au bruit, des niveaux d'exposition au dioxyde d'azote et de la dose totale inhalée de dioxyde d'azote. Nous vous proposons ici d'analyser une partie de ces données.\n\n\n#### Première ANOVA : différences entre les temps de déplacement {#sec-06231}\nComme première analyse de variance, nous vérifions si les moyennes des temps de déplacement sont différentes entre les trois modes de transport. \n\nDans un premier temps, nous calculons les moyennes des différents groupes. Nous pouvons alors constater que les moyennes sont très semblables : 37,7 minutes pour l'automobile versus 38,4 et 41,6 pour le vélo et le transport en commun. Aussi, les variances des trois groupes sont relativement similaires.\n\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"rstatix\")\n# chargement des DataFrames\nload(\"data/bivariee/dataPollution.RData\")\n# Statistiques descriptives pour les groupes (moyenne et écart-type)\ndf_TrajetsDuree %>%                                 # Nom du DataFrame\n    group_by(Mode) %>%                                # Variable qualitative\n    get_summary_stats(DureeMinute, type = \"mean_sd\")  # Variable continue \n```\n\nPour visualiser la distribution des données pour les trois groupes, vous pouvez créer des graphiques de densité et en violon (@fig-Anova1a). La juxtaposition des trois distributions montre que les distributions des valeurs pour les trois groupes sont globalement similaires. Cela est corroboré par le fait que les boîtes du graphique en violon sont situées à la même hauteur. Autrement dit, à la lecture des deux graphiques, il ne semble pas y avoir de différences significatives entre les trois groupes en termes de temps de déplacement.\n\n```{r}\n#| label: fig-Anova1a\n#| echo: true\n#| message: false\n#| warning: false\n#| fig-align: center\n#| fig-cap: Graphiques de densité et en violon\n#| out-width: \"75%\"\nlibrary(\"ggplot2\")\nlibrary(\"ggpubr\")\n# Graphique de densité\nGraphDens <- ggplot(data = df_TrajetsDuree, \n  mapping=aes(x = DureeMinute, colour = Mode, fill = Mode)) +\n  geom_density(alpha=0.55, mapping=aes(y = ..scaled..))+\n    labs(title = \"a. Graphique de densité\",\n         x = \"Densité\",\n         y = \"Durée du trajet (en minutes)\")\n# Graphique en violon\nGraphViolon <- ggplot(df_TrajetsDuree, aes(x = Mode, y = DureeMinute)) +\n  geom_violin(fill = \"white\") +\n  geom_boxplot(width=0.1, aes(x = Mode, y = DureeMinute, fill = Mode))+\n  labs(title = \"b. Graphique en violon\",\n       x = \"Mode de transport\",\n       y = \"Durée du trajet (en minutes)\")+\n  theme(legend.position = \"none\")\nggarrange(GraphDens, GraphViolon)\n``` \n\nNous pouvons vérifier si les échantillons sont normalement distribués avec la fonction `shapiro_test` du package `rstatix`. À titre de rappel, l'hypothèse nulle (*H~0~*) de ce test est que la distribution est normale. Par conséquent, quand la valeur de *p* associée à la statistique de Shapiro est supérieure à 0,05, alors nous ne pouvons rejeter l'hypothèse d'une distribution normale (autrement dit, la distribution est anormale). À la lecture des résultats ci-dessous, seul le groupe utilisant le transport en commun présente une distribution proche de la normalité (*p* = 0,0504). Ce test étant très restrictif, il est fortement conseillé de visualiser le diagramme quantile-quantile pour chaque groupe (graphique QQ plot) (@fig-Qqplot). Ces graphiques sont utilisés pour déterminer visuellement si une distribution empirique (observée sur des données), s'approche d'une distribution théorique (ici la loi normale). Si effectivement les deux distributions sont proches, les points du diagramme devraient tous tomber sur une ligne droite parfaite. Un intervalle de confiance (représenté ici en gris) peut être construit pour obtenir une interprétation plus nuancée. Dans notre cas, seules deux observations pour le vélo et deux autres pour l'automobile s'éloignent vraiment de la ligne droite. Nous pouvons considérer que ces trois distributions s'approchent d'une distribution normale.\n\n```{r}\n#| label: fig-Qqplot\n#| echo: true\n#| message: false\n#| warning: false\n#| fig-align: center\n#| fig-cap: QQ Plot pour les groupes\n#| out-width: \"75%\"\nlibrary(\"dplyr\")\nlibrary(\"ggpubr\")\nlibrary(\"rstatix\")\n# Condition 1 : normalité des échantillons\n# Test pour la normalité des échantillons (groupes) : test de Shapiro\n df_TrajetsDuree %>%          # Nom du DataFrame\n   group_by(Mode) %>%         # Variable qualitative\n   shapiro_test(DureeMinute)  # Variable continue \n# Graphiques qqplot pour les groupes\nggqqplot(df_TrajetsDuree, \"DureeMinute\", facet.by = \"Mode\", \n         xlab = \"Théorique\", ylab = \"Échantillon\")\n\n``` \n\nPour vérifier l’hypothèse d’homogénéité des variances, vous pouvez utiliser les tests de Levene, de Bartlett ou de Breusch-Pagan. Les valeurs de *p*, toutes supérieures à 0,05, signalent que la condition d'homogénéité des variances est respectée.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"rstatix\")\nlibrary(\"lmtest\")\nlibrary(\"car\")\n# Condition 2 : homogénéité des variances (homocédasticité)\nleveneTest(DureeMinute ~ Mode, data = df_TrajetsDuree)\nbartlett.test(DureeMinute ~ Mode, data = df_TrajetsDuree)\nbptest(DureeMinute ~ Mode, data = df_TrajetsDuree)\n```\n\nDeux fonctions peuvent être utilisées pour calculer l'analyse de variance : la fonction de base `aov(variable continue ~ variable qualitative, data = votre DataFrame)` ou bien la fonction `anova_test(variable continue ~ variable qualitative, data = votre DataFrame)` du package `rstatix`. Comparativement à `aov`, l'avantage de la fonction `anova_test` est qu'elle calcule aussi le *Eta^2^*.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"rstatix\")\nlibrary(\"car\")\nlibrary(\"effectsize\")\n# ANOVA avec la fonction aov\naov1 <- aov(DureeMinute ~ Mode, data = df_TrajetsDuree)\nsummary(aov1)\n# calcul de Eta2 avec la fonction eta_squared du package effectsize\neffectsize::eta_squared(aov1)\n# ANOVA avec la fonction anova_test du package rstatix\nanova_test(DureeMinute ~ Mode, data = df_TrajetsDuree)\n```\n\nLa valeur de *p* associée à la statistique *F* (0,444) nous permet de conclure qu'il n'y a pas de différences significatives entre les moyennes des temps de déplacement des trois modes de transport.\n\n#### Deuxième ANOVA : différences entre les niveaux d'exposition au bruit {#sec-06232}\n\nDans ce second exercice, nous analysons les différences d'exposition au bruit. D'emblée, les statistiques descriptives révèlent que les moyennes sont dissemblables : 66,8 dB(A) pour l’automobile versus 68,8 et 74 pour le vélo et le transport en commun. Aussi, la variance du transport en commun est très différente des autres.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"rstatix\")\n# chargement des DataFrames\nload(\"data/bivariee/dataPollution.RData\")\n# Statistiques descriptives pour les groupes (moyenne et écart-type)\n df_Bruit %>%                                 # Nom du DataFrame\n   group_by(Mode) %>%                                # Variable qualitative\n   get_summary_stats(laeq, type = \"mean_sd\")  # Variable continue \n```\n\nÀ la lecture des graphiques de densité et en violon (@fig-Anova1b), il semble clair que les niveaux d'exposition au bruit sont plus faibles pour les automobilistes et plus élevés pour les cyclistes et surtout les personnes en transport en commun. En outre, la distribution des valeurs d'exposition au bruit dans le transport en commun semble bimodale. Cela s'explique par le fait que les niveaux de bruit sont beaucoup plus élevés dans le métro que dans les autobus.\n\n```{r}\n#| label: fig-Anova1b\n#| echo: true\n#| message: false\n#| warning: false\n#| fig-align: center\n#| fig-cap: Graphique de densité et en violon\n#| out-width: \"75%\"\nlibrary(\"ggplot2\")\nlibrary(\"ggpubr\")\n# Graphique en densité\nGraphDens <- ggplot(data = df_Bruit, \n  mapping=aes(x = laeq, colour = Mode, fill = Mode)) +\n  geom_density(alpha=0.55, mapping=aes(y = ..scaled..))+\n  labs(title = \"a. graphique de densité\",\n       x = \"Exposition au bruit (dB(A))\")\n# Graphique en violon\nGraphViolon <- ggplot(df_Bruit, aes(x = Mode, y = laeq)) +\n  geom_violin(fill = \"white\") +\n  geom_boxplot(width=0.1, aes(x = Mode, y = laeq, fill = Mode))+\n  labs(title = \"b. Graphique en violon\",\n       x = \"Mode de transport\",\n       y = \"Exposition au bruit (dB(A))\")+\n  theme(legend.position = \"none\")\nggarrange(GraphDens, GraphViolon)\n``` \n\n\nLe test de Shapiro et les graphiques QQ plot (@fig-Qqplot2) révèlent que les distributions des trois groupes sont anormales. Ce résultat n'est pas surprenant si l'on tient compte de la nature logarithmique de l'échelle décibel.\n\n```{r}\n#| label: fig-Qqplot2\n#| echo: true\n#| message: false\n#| warning: false\n#| fig-align: center\n#| fig-cap: QQ Plot pour les groupes\n#| out-width: \"75%\"\nlibrary(\"dplyr\")\nlibrary(\"ggpubr\")\nlibrary(\"rstatix\")\n# Condition 1 : normalité des échantillons\n# Test pour la normalité des échantillons (groupes) : test de Shapiro\ndf_Bruit %>%          # Nom du DataFrame\n  group_by(Mode) %>%         # Variable qualitative\n  shapiro_test(laeq)  # Variable continue \n# Graphiques qqplot pour les groupes\nggqqplot(df_Bruit, \"laeq\", facet.by = \"Mode\", xlab = \"Théorique\", ylab = \"Échantillon\")\n\n``` \n\nEn outre, selon les valeurs des tests de Levene, de Bartlett ou de Breusch-Pagan, les variances ne sont pas égales.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"rstatix\")\nlibrary(\"lmtest\")\nlibrary(\"car\")\n# Condition 2 : homogénéité des variances (homocédasticité)\nleveneTest(laeq ~ Mode, data = df_Bruit)\nbartlett.test(laeq ~ Mode, data = df_Bruit)\nbptest(laeq ~ Mode, data = df_Bruit)\n```\n\nÉtant donné que les deux conditions (normalité et homogénéité des variances) ne sont pas respectées, il est préférable d'utiliser un test non paramétrique de Kruskal-Wallis. Calculons toutefois préalablement l'ANOVA classique et l'ANOVA de Welch puisque les variances ne sont pas égales. Les valeurs de *p* des deux tests (Fisher et Welch) signalent que les moyennes d'exposition au bruit sont statistiquement différentes entre les trois modes de transport.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\nlibrary(\"rstatix\")\n# ANOVA avec la fonction anova_test du package rstatix\nanova_test(laeq ~ Mode, data = df_Bruit)\n# ANOVA avec le test de Welch puisque les variances ne sont pas égales\nwelch_anova_test(laeq ~ Mode, data = df_Bruit)\n```\n\nUne fois démontré que les moyennes sont différentes, le test de Tukey est particulièrement intéressant puisqu'il nous permet de repérer les différences de moyennes significatives deux à deux, tout en ajustant les valeurs de *p* obtenues en fonction du nombre de comparaisons effectuées. Ci-dessous, nous constatons que toutes les paires sont statistiquement différentes et que la différence de moyennes entre les automobilistes et les cyclistes est de 1,9 dB(A) et surtout de 7,1 dB(A) entre les automobilistes et les personnes ayant pris le transport en commun.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\naov2 <- aov(laeq ~ Mode, data = df_Bruit)\n# Test de Tukey pour comparer les moyennes entre elles\nTukeyHSD(aov2, conf.level = 0.95)\n```\n\nLe calcul du test non paramétrique de Kruskal-Wallis avec la fonction `kruskal.test` démontre aussi que les médianes des groupes sont différentes (*p* < 0,001). De manière comparable au test de Tukey, la fonction `pairwise.wilcox.test` permet aussi de repérer les différences significatives entre les paires de groupes. Pour conclure, tant l'ANOVA que le test non paramétrique de Kruskal-Wallis indiquent que les trois modes de transport sont significativement différents quant à l'exposition au bruit, avec des valeurs plus faibles pour les automobilistes comparativement aux cyclistes et aux personnes ayant pris le transport en commun.\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\n# Test de Kruskal-Wallis\nkruskal.test(laeq ~ Mode, data = df_Bruit)\n# Calcul de la moyenne des rangs pour les trois groupes\ndf_Bruit$laeqRank <- rank(df_Bruit$laeq)\ndf_Bruit %>%\n  group_by(Mode) %>%\n  get_summary_stats(laeqRank, type = \"mean\")\n# Comparaison des groupes avec la fonction pairwise.wilcox.test\npairwise.wilcox.test(df_Bruit$laeq, df_Bruit$Mode, p.adjust.method = \"BH\")\n```\n\n### Comment rapporter les résultats d'une ANOVA et du test de Kruskal-Wallis {#sec-0624}\n\nPlusieurs éléments doivent être reportés pour détailler les résultats d'une ANOVA ou d'un test de Kruskal-Wallis : la valeur de *F*, de *W* (dans le cas d'une ANOVA de Welch) ou du χ2 (Kruskal-Wallis), les valeurs de *p*, les moyennes ou médianes respectives des groupes et éventuellement un tableau détaillant les écarts intergroupes obtenus avec les tests de Tukey ou Wilcoxon par paires.\n\n* Les résultats de l'analyse de variance à un facteur démontrent que le mode de transport utilisé n'a pas d'effet significatif sur le temps de déplacement en heures de pointe à Montréal (*F*(2,96) = 0,82, *p* = 0,444). En effet, pour des trajets de dix kilomètres entre un quartier périphérique et le centre-ville, les cyclistes (Moy = 38,4, ET = 15,2) arrivent en moyenne moins d'une minute après les automobilistes (Moy = 37,7, ET = 12,8) et moins de quatre minutes comparativement aux personnes ayant pris le transport en commun (Moy = 41,6, ET = 11,4). \n\n* Les résultats de l'analyse de variance à un facteur démontrent que le mode de transport utilisé a un impact significatif sur le niveau d'exposition en heures de pointe à Montréal (*F*(2,96) = 544, *p* < 0,001 et *Welch*(2,96) = 446, *p* < 0,001). En effet, les personnes en transport en commun (Moy = 74,0, ET = 6,79) et les cyclistes (Moy = 68,8, ET = 4,3) ont des niveaux d'exposition au bruit significativement plus élevés que les automobilistes (Moy = 66,8, ET = 4,56). \n\n* Les résultats du test de Kruskal-Wallis démontrent qu'il existe des différences significatives d'exposition au bruit entre les trois modes de transport (χ2(2) = 784,74, *p* < 0,001) avec des moyennes de rangs de 1094 pour l'automobile, de 1124 pour le vélo et de 1207 pour le transport en commun.\n\n::: bloc_aller_loin\n::: bloc_aller_loin-header\n::: bloc_aller_loin-icon\n:::\n**Autres extensions de l'ANOVA**\n:::\n::: bloc_aller_loin-body\nNous avons vu que l'ANOVA permet de comparer les moyennes d'une variable continue à partir d'une variable qualitative comprenant plusieurs modalités (facteur) pour des observations indépendantes. Il y a donc une seule variable dépendante (continue) et une seule variable indépendante. Sachez qu'il existe de nombreuses extensions de l'ANOVA classique : \n\n* **Une ANOVA à deux facteurs**, soit avec une variable dépendante continue et deux variables indépendantes qualitatives (_two-way ANOVA_ en anglais). Nous évaluons ainsi les effets des deux variables (*a*, *b*) et de leur interaction (*ab*) sur une variable continue.\n\n* **Une ANOVA multifacteur** avec une variable dépendante continue et plus de deux variables indépendantes qualitatives. Par exemple, avec trois variables qualitatives pour expliquer la variable continue, nous incluons les effets de chaque variable qualitative (*a*, *b*, *c*), ainsi que de leurs interactions (*ab*, *ac*, *bc*, *abc*).\n\n* **L'analyse de covariance** (**ANCOVA**, _**AN**alysis of **COVA**riance_ en anglais) comprend une variable dépendante continue, une variable indépendante qualitative (facteur) et plusieurs variables indépendantes continues dites covariables. L'objectif est alors de vérifier si les moyennes d'une variable dépendante sont différentes pour plusieurs groupes d'une population donnée, après avoir contrôlé l'effet d'une ou de plusieurs variables continues. Par exemple, pour une métropole donnée, nous pourrions vouloir comparer les moyennes de loyers entre la ville-centre et ceux des première et seconde couronnes (facteur), une fois contrôlée la taille de ces derniers (variable covariée continue). En effet, une partie de la variance des loyers s'explique certainement par la taille des logements.\n\n* **L'analyse de variance multivariée** (**MANOVA**, _**M**ultivariate **AN**alysis **O**f **VA**riance_ en anglais) comprend deux variables dépendantes continues ou plus et une variable indépendante qualitative (facteur). Par exemple, nous souhaiterions comparer les moyennes d'exposition au bruit et à différents polluants (dioxyde d'azote, particules fines, ozone) (variables dépendantes continues) selon le mode de transport utilisé (automobile, vélo, transport en commun), soit le facteur.\n\n* **L'analyse de covariance multivariée** (**MANCOVA**, _**M**ultivariate **AN**alysis of **COVA**riance_ en anglais), soit une analyse qui comprend deux variables dépendantes continues ou plus (comme la MANOVA) et une variable qualitative comme variable indépendante (facteur) et une covariable continue ou plus.\n\nPour le test *t*, nous avons vu qu'il peut s'appliquer soit à deux échantillons indépendants (non appariés), soit à deux échantillons dépendants (appariés). Notez qu'il existe aussi des extensions de l'ANOVA pour des échantillons pairés. Nous parlons alors d'**analyse de variance sur des mesures répétées**. Par exemple, nous pourrions évaluer la perception du sentiment de sécurité relativement à la pratique du vélo d'hiver pour un échantillon de cyclistes ayant décidé de l'adopter récemment, et ce, à plusieurs moments : avant leur première saison, à la fin de leur premier hiver, à la fin de leur second hiver. Autre exemple, nous pourrions sélectionner un échantillon d'individus (100, par exemple) pour lesquels nous évaluerions leurs perceptions de l'environnement sonore dans différents lieux de la ville. Comme pour l'ANOVA classique (échantillons non appariés), il existe des extensions de l'ANOVA sur des mesures répétées permettant d'inclure plusieurs facteurs (groupes de population); nous mesurons alors une variable continue pour plusieurs groupes d'individus à différents moments ou pour des conditions différentes. Il est aussi possible de réaliser une ANOVA pour des mesures répétées avec une ou plusieurs covariables continues. \n\nBref, si l'ANOVA était un roman, elle serait certainement « un monde sans fin » de Ken Follett! Notez toutefois que la SUPERNOVA, la BOSSA-NOVA et le CASANOVA ne sont pas des variantes de l'ANOVA!\n:::\n:::\n\n\n## Conclusion sur la troisième partie {#sec-063}\n\nDans le cadre de cette troisième partie du livre, nous avons abordé les principales méthodes exploratoires et confirmatoires bivariées permettant d’évaluer la relation entre deux variables. La @fig-PrincipalesAnalysesBivariees propose un résumé de ces méthodes.\n\n![Principales méthodes bivariées](images/Chap06/PrincipalesMethoBivariees.jpg){#fig-PrincipalesAnalysesBivariees width=\"65%\" fig-align=\"center\"}\n\n## Quiz de révision du chapitre {#sec-064}\n\n```{r}\n#| label: Chapitre6QualiQuanti\n#| echo: false\n#| warning: false\n#| results: asis\nsource(\"code_complementaire/QuizzFunctions.R\")\nChapitre6_QualiQuanti <- quizz(\"quiz/Chapitre6_QualiQuanti.yml\", \"Chapitre6_QualiQuanti\")\nrender_quizz(Chapitre6_QualiQuanti)\n```\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["css/quizlib.min.css"],"output-file":"06-bivarieeQualiQuanti.html"},"language":{"toc-title-document":"Table des matières","toc-title-website":"Sur cette page","related-formats-title":"Autres formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"La source","section-title-abstract":"Résumé","section-title-appendices":"Annexes","section-title-footnotes":"Notes de bas de page","section-title-references":"Les références","section-title-reuse":"Réutilisation","section-title-copyright":"Droits d'auteur","section-title-citation":"Citation","appendix-attribution-cite-as":"Veuillez citer ce travail comme suit :","appendix-attribution-bibtex":"BibTeX","title-block-author-single":"Auteur·rice","title-block-author-plural":"Auteurs","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Date de publication","title-block-modified":"Modifié","callout-tip-title":"Astuce","callout-note-title":"Note","callout-warning-title":"Avertissement","callout-important-title":"Important","callout-caution-title":"Mise en garde","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Montrer tout le code","code-tools-hide-all-code":"Cacher tout le code","code-tools-view-source":"Voir les sources","code-tools-source-code":"Code source","code-line":"Ligne","code-lines":"Lignes","copy-button-tooltip":"Copier vers le presse-papier","copy-button-tooltip-success":"Copié","repo-action-links-edit":"Modifier cette page","repo-action-links-source":"Voir la source","repo-action-links-issue":"Signaler un problème ou<br>formuler une suggestion","back-to-top":"Retour au sommet","search-no-results-text":"Pas de résultats","search-matching-documents-text":"documents trouvés","search-copy-link-title":"Copier le lien vers la recherche","search-hide-matches-text":"Cacher les correspondances additionnelles","search-more-match-text":"correspondance de plus dans ce document","search-more-matches-text":"correspondances de plus dans ce document","search-clear-button-title":"Effacer","search-detached-cancel-button-title":"Annuler","search-submit-button-title":"Envoyer","search":"Recherche","toggle-section":"Basculer la section","toggle-sidebar":"Basculer la barre latérale","toggle-dark-mode":"Basculer le mode sombre","toggle-reader-mode":"Basculer en mode lecteur","toggle-navigation":"Basculer la navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Théorème","crossref-lem-title":"Lemme","crossref-cor-title":"Corollaire","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Définition","crossref-exm-title":"Exemple","crossref-exr-title":"Exercice","crossref-ch-prefix":"Chapitre","crossref-apx-prefix":"Annexe","crossref-sec-prefix":"Section","crossref-eq-prefix":"Équation","crossref-lof-title":"Liste des Figures","crossref-lot-title":"Liste des Tables","crossref-lol-title":"Liste des Listings","environment-proof-title":"Preuve","environment-remark-title":"Remarque","environment-solution-title":"Solution","listing-page-order-by":"Trier par","listing-page-order-by-default":"Ordre par défaut","listing-page-order-by-date-asc":"Le plus ancien","listing-page-order-by-date-desc":"Le plus récent","listing-page-order-by-number-desc":"Descendant","listing-page-order-by-number-asc":"Ascendant","listing-page-field-date":"Date","listing-page-field-title":"Titre","listing-page-field-description":"Description","listing-page-field-author":"Auteur·rice","listing-page-field-filename":"Nom de fichier","listing-page-field-filemodified":"Modifié","listing-page-field-subtitle":"Sous-titre","listing-page-field-readingtime":"Temps de lecture","listing-page-field-categories":"Catégories","listing-page-minutes-compact":"{0} min.","listing-page-category-all":"Tous","listing-page-no-matches":"Aucun article correspondant"},"metadata":{"lang":"fr","fig-responsive":true,"quarto-version":"1.3.353","license":"CC BY-SA","crossref":{"fig-prefix":"figure","tbl-prefix":"tableau","sec-prefix":"section","eq-prefix":"équation","fig-title":"Figure","tbl-title":"Tableau","eq-title":"Équation"},"bibliography":["references.bib"],"csl":"StyleINRS.csl","colorlinks":true,"theme":{"light":["cosmo","css/r4ds.scss"]},"fontsize":"11pt","mainfont":"Helvetica Neue,Helvetica,Arial,sans-serif","monofont":"SFMono-Regular,Menlo,Monaco,Consolas,\"Liberation Mono\",\"Courier New\",monospace"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}