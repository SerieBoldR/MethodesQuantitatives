# Régressions à effets mixtes (GLMM) et régression multiniveaux  {#chap07}

Dans les deux chapitres précédents, nous avons consécutivement présenté la méthode de la régression linéaire simple (LM) ainsi que son extension : les modèles linéaires généralisés (GLM). Dans ce chapitre, nous poursuivons sur cette voie avec deux nouvelles extensions : les modèles généralisés à effet mixtes et les modèles multiniveaux.

## Introduction

### Indépendance des observations et effets de groupes

Nous avons vu dans les précédents chapitres que l'indépendance des observations est une condition d'application commune à l'ensemble des modèles de régression. Cette condition implique ainsi que chaque unité d'observation de notre jeu de données est indépendante des autres ; en d'autres termes, qu'elle ne soit associée à aucune autre observation par un lien de dépendance. Prenons un exemple concret pour illustrer cette notion. Admettons que nous nous intéressons à la performance scolaire d'élèves de secondaire à Montréal. Pour cela, nous collectons la moyenne des résultats aux examens du Ministère de tous les élèves des différentes commissions scolaires de l'île de Montréal. Chaque élève appartient à une classe spécifique, et chaque classe se situe dans une école spécifique. Les classes constituent des environnements particuliers, la performance des élèves y est influencée par un ensemble de facteurs comme l'enseignant et les relations entre les élèves d'une même classe. Deux élèves provenant d'une même classe sont donc liés par une forme de structure propre à leur classe et ne peuvent pas être considérés comme indépendants. De même, l'école constitue un environnement particulier pouvant influencer la performance des élèves du fait de moyens financiers plus importants, de la mise en place de programmes spéciaux, de la qualité des infrastructures (bâtiment, gymnase, cour d'école) ou d'une localisation minimisant certaines nuisances à l'apprentissage comme le bruit. À nouveau, deux élèves provenant d'une même école partagent une forme de structure qui cette fois-ci est propre à leur école. Si nous collections des données pour l'ensemble du Canada, nous pourrions étendre ce raisonnement aux villes dans lesquelles les écoles se situent et aux provinces.

Dans cet exemple, la dépendance entre les données est provoquée par un effet de groupe : il est possible de rassembler les observations dans des ensembles (classes et écoles) influençant vraisemblablement la variable étudiée (performance scolaire). Les effets des classes et des écoles ne sont cependant pas intrinsèques aux élèves. En effet, il est possible de changer un élève de classe ou d'école, mais pas de changer son sexe, ou sa situation familiale. Il est ainsi possible de distinguer la population des élèves, la population des classes, et la population des écoles (\@ref(fig:glmmecoles)). Ces effets de groupes sont plus la règle que l'exception dans l'analyse de données en sciences sociales, ce qui met à mal l'hypothèse d'indépendance des observations. Notez que les effets de groupes ne sont pas les seules formes de structures remettant en cause l'indépendance des observations. Il existe également des structures temporelles (deux observations proches dans le temps ont plus de chances de se ressembler) et spatiales (deux observations proches dans l'espace ont plus de chances de se ressembler). Cependant, le cas de la dépendance temporelle et spatiale n'est pas couvert dans ce livre, car complexes et elles mériteraient un ouvrage dédié.

```{r glmmecoles, echo=FALSE, fig.align='center', fig.cap="Structure hiérarchique entre élèves, classes et écoles", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
knitr::include_graphics('images/glmm/Hierarchie_Ecoles.png', dpi = NA)
```

::: {.bloc_aller_loin data-latex=""}
**La notion de pseudo-réplication**

Les effets de dépendance causés par des structures de groupes, temporelles ou spatiales sont regroupées sous le terme de pseudo-réplication. Il est intéressant de se pencher sur la signification de ce mot pour comprendre le problème intrinsèque causé par la dépendance entre les observations et son impact sur l'inférence.

Reprenons l'exemple des élèves et de la performance scolaire et admettons que nous souhaitons estimer la moyenne générale de l'ensemble des élèves sur l'île de Montréal, mais que nous ne disposons pas du jeu de données complet. Nous devons donc collecter un échantillon suffisamment grand pour estimer la moyenne pour l'ensemble de cette population. Raisonnons en termes de quantité d'informations. Si nous ne disposons d'aucune observation (nous n'avons encore interrogé aucun élève), cette quantité est de 0. Si nous interrogeons un premier élève, nous obtenons une donnée supplémentaire et donc un point d'information supplémentaire (+1). Admettons maintenant que nous collectons 30 observations dans une école, 10 dans une seconde et 5 dans une troisième. A priori, nous pourrions dire que nous avons ajouté 45 points d'information à notre total de connaissance. Ce serait le cas si les observations étaient indépendantes les unes des autres. Dans un tel contexte, chaque observation ajoute la même quantité d'information. Cependant, puisque les élèves issus d'une même école ont plus de chance de se ressembler, interroger les élèves d'une même école apporte moins d'information. Notez que plus la ressemblance entre les élèves d'une même école est forte, plus la quantité d'information est réduite. Nous sommes donc loin de disposer d'une quantité d'information égale à 45. Chaque réplication de l'expérience (demander à un élève sa moyenne annuelle) n'apporte pas autant d'information qu'attendu si les observations étaient indépendantes, c'est pourquoi on parle de **pseudo-réplication**.

La pseudo-réplication impacte directement l'inférence statistique puisque le calcul des différents tests statistiques assume que chaque observation apporte autant d'information que les autres. En cas de présence de pseudo-réplication, la quantité d'information présente dans l'échantillon est plus petite qu'attendu. Il est possible de voir cela comme une forme de surestimation de la taille de l'échantillon. En cas de pseudo-réplication nous disposons en réalité de moins de données que ce que l'on attendrait d'un échantillon de cette taille si les observations étaient indépendantes. La conséquence est la sous-estimation de la variabilité réelle des données et l'augmentation des risques de trouver des effets significatifs dans l'échantillon alors qu'ils ne le sont pas pour l'ensemble de la population.

:::

### Terminologie : effets fixes et effets aléatoires

Puisque les effets des classes et des écoles ne sont pas propres aux élèves, il convient de les introduire différemment dans les modèles de régression. Nous appelons un effet fixe, un effet qui est propre aux observations que nous étudions et un effet aléatoire, un effet provoqué par une structure externe (effet de groupe, effet temporel, effet spatial). Un modèle combinant à la fois des effets fixes et des effets aléatoires est appelé un **modèle à effets mixtes**, ou GLMM pour *Generalized Linear Mixed Model*. En sciences sociales, on utilise aussi souvent le terme de modèle hiérarchique ou multiniveau. Tous les modèles que nous avons ajustés dans les sections précédentes ne comprenaient que des effets fixes alors qu'à plusieurs reprises, des effets aléatoires induits par l'existence de structure de groupe auraient pu (dû) être utilisés. Prenons pour exemple le modèle logistique binomial visant à prédire la probabilité d'utiliser le vélo comme mode de transport pour son trajet le plus fréquent (REF). La variable multinomiale *Pays*, représentant le pays dans lequel les personnes interrogées résident a été introduite comme un effet fixe. Cependant, l'effet du pays ne constitue pas une caractéristique propre aux individus, il s'agit plutôt d'un agrégat complexe mêlant culture, météorologie, orientation des politiques publiques et formes urbaines. À l'inverse, le sexe ou l'âge sont bien des caractéristiques intrinsèques des individus et peuvent être considérés comme des effets fixes.

Notez que l'utilisation du terme effet aléatoire peut porter à confusion, car différentes utilisations en sont faites en fonction du champ d'études. Parmi les différentes définitions relevées par @gelman2005analysis d'un effet aléatoire, il est possible de retrouver les suivantes : 

* Les effets fixes sont identiques pour tous les individus alors que les effets aléatoires varient (définition 1).

* Les effets sont fixes s'ils sont intéressants en eux-mêmes, et les effets sont aléatoires si on s'intéresse à la population dont ils sont issus (définition 2).

* Lorsqu'un échantillon couvre une grande part de la population, la variable correspondante est un effet fixe. Si l'échantillon couvre une faible part de la population, l'effet est aléatoire (définition 3).

* Si l'effet est supposé provenir d'une variable aléatoire, alors il s'agit d'un effet aléatoire (définition 4).

* Les effets fixes sont estimés par la méthode des moindres carrés par maximum de vraisemblance alors que les effets aléatoires sont estimés avec régularisation (*shrinkage*) (définition 5).

Il est ainsi possible de se retrouver dans des cas où un effet serait classé comme fixe selon une définition et aléatoire selon une autre. La deuxième définition suppose même qu'un effet peut être aléatoire ou fixe selon l'objectif central de l'étude. La dernière définition a l'avantage d'être mathématique, mais ne permet pas de décider si un effet doit être traité comme aléatoire ou fixe. Nous ne proposons pas ici de clore le débat, mais plutôt de donner quelques pistes de réflexion pour décider si un effet doit être modélisé comme fixe ou aléatoire :

* Est-ce que l'effet en question est propre aux individus étudiés ou est externe aux individus. S'il est propre aux individus, il s'agit plus certainement d'un effet fixe. À titre d'exemple, on ne peut pas changer le sexe d'un individu, mais on peut certainement changer sa ville de résidence.
* Existe-t-il un nombre bien arrêté de catégories possibles pour l'effet en question ? Si oui, il s'agit plus certainement d'un effet fixe. Toujours avec le même exemple, il y a un nombre bien arrêté de catégories pour la variable sexe, mais pour la variable pays, de nombreuses autres valeurs auraient pu être ajoutées. Il est également possible de se demander s'il semble cohérent d'effectuer un échantillonnage sur les catégories en question. Dans le cas des pays, nous pourrions mener une étude à l'échelle des pays et collecter des données sur un échantillon de l'ensemble des pays. Il existe donc une population de pays, ce que nous ne pouvons pas affirmer pour la variable sexe.
* L'effet en question est direct ou indirect ? Dans le second cas, l'effet en question est un agglomérat complexe découlant de plusieurs processus n'ayant pas été mesurés directement, ce qui correspond davantage à un effet aléatoire. Ainsi, l'effet du pays de résidence des individus sur leur probabilité d'utiliser le vélo est bien une agglomération complexe d'effets (culture, météorologie, orientation des politiques publiques, formes urbaines, etc.) n'ayant pas tous été mesurés. À l'inverse, l'âge d'un individu a bien un effet direct sur sa probabilité d'utiliser le vélo.
* L'effet est-il le même pour tous les individus, ou doit-il varier selon le groupe dans lequel l'individu se situe ? Si un effet doit varier en fonction d'un groupe, il s'apparente davantage à un effet aléatoire. Pour reprendre l'exemple de l'âge, nous pourrions décider que cette caractéristique des individus n'a peut-être pas le même impact en fonction du pays dans lequel vit l'individu et l'ajouter au modèle comme un effet aléatoire.

Vous comprendrez donc qu'une partie non négligeable du choix entre effet fixe ou aléatoire réside dans le cadre théorique à l'origine du modèle. Maintenant que cette distinction conceptuelle a été détaillée, nous pouvons passer à la présentation statistique des modèles GLMM.

## Principes de base des GLMM {#sect071}

Un GLMM est donc un modèle GLM introduisant à la fois des effets fixes et des effets aléatoires. Si l'on ne considère que les effets de groupes, un GLMM peut avoir trois formes : constantes aléatoires, pentes aléatoires et constantes et pentes aléatoires. Nous présentons ces trois formes ici en reprenant l'exemple théorique ci-dessus avec des élèves intégrés dans des classes pour lesquels nous nous intéressons à leur niveau de performance à l'examen ministériel de mathématique.

### GLMM avec constantes aléatoires

Il s'agit de la forme la plus simple d'un GLMM, plus spécifiquement, elle autorise le modèle à avoir une constante différente pour chaque catégorie d'une variable multinomiale. En d'autres termes, nous tentons d'ajouter dans le modèle l'idée que chaque classe a une moyenne différente en termes de performance à l'examen de mathématique. Il est possible assez facilement de visualiser ce que cela signifie avec un exemple graphique. Admettons que nous modélisons le score obtenu par des élèves de secondaire à l'examen ministériel de mathématique à partir d'une autre variable continue représentant le temps de travail moyen par semaine en dehors des heures de classe et d'une variable catégorielle représentant dans quelle classe se trouve chaque élève. Notez qu'il ne s'agit pas ici de vraies données, mais de simples simulations utilisées à titre d'illustration. Si nous ne tenons pas compte des classes nous pouvons ajuster une simple régression linéaire entre nos deux variables continues comme le propose la figure \@ref(fig:randominter1).

```{r randominter1, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

set.seed(11)
library(ggplot2)

## Générer des effets aléatoires
groups <-  c("A","B","C","D","E","F","G","H")
sig2 <- matrix(c(12, 0.1,
                 0.1, 0.5), 
               nrow = 2, ncol = 2)
mu2 <- c(inter = 0, coeff = 0)
df2 <- data.frame(data.frame(MASS::mvrnorm(n = length(groups), mu = mu2, Sigma = sig2)))
df2$name <- groups

colors <- hcl.colors(length(groups), palette = "Dynamic")
names(colors) <- groups

## Générer des données
n <- 300
df <- data.frame(
  X = rnorm(n,8,2),
  group = sample(df2$name,size = n, replace = T)
)

df3 <- merge(df,df2, by.x="group",by.y="name")
df3$Y <- 65 + df3$X*(1.5+df3$coeff) + df3$inter + rnorm(n = n, mean = 0, sd = 8)
df3$Y2 <- ifelse(df3$Y>=100, 100, df3$Y)

## Afficher le tout !
ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), size = 1) + 
  geom_smooth(aes(x = X, y = Y2),method='lm', formula= y~x, se=F, color = "black", size = 1.2)+
  scale_color_manual(values = colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

On constate que notre modèle semble bien identifier la relation positive entre le temps de travail et le niveau de performance, mais la droite de régression est très éloignée de chaque point, nous avons donc énormément d'erreurs de prédiction et donc des résidus importants. Jusqu'ici nous avons vu que nous pouvions ajouter un prédicteur et intégrer l'effet des classes comme un effet fixe.

```{r randominter2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + group, data = df3)
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- diffs + model$coefficients[[1]]

df4 <- data.frame(
  inter = diffs,
  slope = b1,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

Cet ajustement constitue une nette amélioration du modèle. Prenons un instant pour reformuler clairement notre modèle à effets fixes : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_j x_{2j}}\\
&g(x) = x
\end{aligned}
(\#eq:glmm1)
\end{equation}
\normalsize

avec $x_1$ le temps de travail et $x_2$ la classe ayant *k-1* modalités (puisqu'une modalité est la référence). Nous  ajustons ainsi un coefficient pour chaque classe qui va avoir pour effet de tirer vers le haut ou vers le bas la prédiction du modèle en fonction de la classe. Cet effet est pour l'instant fixe, mais conceptuellement, nous avons déterminé dans les sections précédentes qu'il serait conceptuellement plus approprié de le traiter comme un effet aléatoire.

Passons à présent à la reformulation de ce modèle en transformant l'effet fixe de la classe en effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = x
\end{aligned}
(\#eq:glmm2)
\end{equation}
\normalsize

Remarquez que l'effet fixe de la classe $\sum^k_{j=1}{\beta_j x_{2j}}$ a été remplacé par $\upsilon$ qui est un terme aléatoire propre aux classes et qui suit une distribution normale centrée sur 0. En d’autres termes, cela signifie que l'effet des classes sur la performance des élèves suit une distribution normale et que si l'on moyennait l'effet de toutes classes, cet effet serait de 0. Nous ne modélisons donc plus l'effet moyen de chaque classe comme dans le modèle à effets fixes, mais la variabilité de l'effet des classes, soit $\sigma_{\upsilon}$. Notre modèle a donc deux variances, une au niveau des élèves ($\sigma_e$) et une au niveau de classes ($\sigma_{\upsilon}$). Cette particularité explique souvent pourquoi ce type de modèle est appelé un modèle hiérarchique ou un modèle de partition de la variance. Cette information est particulièrement intéressante car elle permet de calculer dans le cas d'un GLMM gaussien, la part de la variance présente au niveau des élèves et celle au niveau des classes.

Selon cette formulation, les constantes propres à chaque classe sont issues d'une distribution normale (nous reviendrons d'ailleurs sur ce choix plus tard), mais elles n'apparaissent pas directement dans le modèle. Ces paramètres ne sont plus estimés directement dans le modèle, mais a posteriori à partir des prédictions du modèle, et sont appelés *Best Linear Unbiased Predictor* (BLUP). Ces dernières précisions devraient d'ailleurs mieux vous aider à comprendre l'origine des définitions 1, 2 et 4 que nous avions mentionnées précédemment.

```{r randominter3, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(lme4)

model2 <- lmer(Y2 ~ X + (1|group), data = df3)

coeffs <- coef(model2)$group
df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values = colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

En comparant les deux graphiques, la différence ne saute pas aux yeux; vous pourriez alors légitimement vous demander pourquoi tous ces efforts et cette complexité théorique pour une différence d'ajustement minime ? Trois arguments permettent de justifier l'utilisation de constantes aléatoire plutôt que d'effets fixes dans notre cas.

#### Resserrement (*shrinkage*) et mutualisation (*partial pooling*)

Le premier intérêt d'utiliser un effet aléatoire réside dans sa méthode d'estimation qui diffère largement d'un effet fixe. Il est assez facile de se représenter intuitivement la différence entre les deux. Dans le cas de nos élèves et de nos classes, lorsque l'effet des classes est estimé avec un effet fixe, l'effet de chaque classe est déterminé de façon totalement indépendante des autres classes. En d'autres termes, il n'est possible d'en apprendre plus sur une classe qu'en collectant des données dans cette classe (*separate pooling*). Si l'effet des classes est estimé comme un effet aléatoire, alors l'information entre les classes est mutualisée (*partial pooling*). L'idée étant que l'information que l'on apprend sur des élèves dans une classe est au moins en partie valide dans les autres classes également. Cette méthode d'estimation est particulièrement intéressante si nous ne disposons que de peu d'observations dans une classe puisque nous pouvons apprendre au moins une partie de l'effet de cette classe à partir des données des autres classes. Ceci n'est pas possible dans le cas d'un effet fixe où l'on traite chaque classe en silo. @mcelreath2020statistical écrit à ce sujet qu'un effet fixe « n'a pas de mémoire » et qu'il oublie tout ce qu'il a appris sur les classes lorsqu'il passe à une nouvelle classe. La conséquence de cette mutualisation de l'information est un resserrement (*shrinkage*) des effets des classes autour de leur moyenne. Cela signifie que les tailles des effets de chaque classe sont plus petites dans le cas d'un effet aléatoire que d'un effet fixe. Utiliser des effets aléatoires conduit donc à une estimation plus conservative de l'effet des classes. Nous pouvons le visualiser en comparant les effets de classes dans le modèle à effets mixtes et le modèle à effet fixes. La figure \@ref(fig:randominter5) montre clairement que les effets aléatoires tendent à se rapprocher (resserrement) de leur moyenne (ligne noire) et donc à renvoyer des effets moins extrêmes pour chaque classe. Cette explication est directement en lien avec la définition 5 d'un effet aléatoire vu précédemment.

```{r randominter5, echo=FALSE, fig.align='center', fig.cap="Comparaison des effets des classes pour le modèle à effets fixes versus le modèle effets aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(MuMIn)

r2s <- r.squaredGLMM(model2)

df6 <- data.frame(
  fixed = df4$inter,
  random = df5$inter,
  group = df4$group
)

ggplot() + 
  geom_point(data = df4, mapping = aes(x = inter, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = inter, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$inter)) + 
  labs(x = "effet de la classe", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

sigma_u <- as.data.frame(VarCorr(model2))$sdcor[[1]]
sigma_e <- as.data.frame(VarCorr(model2))$sdcor[[2]]
```
#### Prédiction pour de nouveaux groupes

Une autre retombée directe de la mutualisation de l'information est la capacité de modèle à envisager les effets plausibles pour de nouvelles classes. En effet, puisque nous avons approximé l'effet des classes sous forme d'une distribution normale dont nous connaissons la moyenne (0) et l'écart type ($\sigma_{\upsilon}$), nous pouvons simuler des données pour de nouvelles classes, ce que ne permet pas un effet fixe. Ce constat est d'ailleurs directement lié à la définition 3 des effets aléatoires vue précédemment. Dans notre cas, $\sigma_{\upsilon}$ = `r tofr(round(sigma_u,3))`, ce qui nous permet d'affirmer que dans 95% des classes, l'effet de la classe sur la performance scolaire doit se trouver entre -1.96 $\times$ `r tofr(round(sigma_u,3))` et +1,96 $\times$ `r tofr(round(sigma_u,3))`, soit l'intervalle [`r tofr(round(-1.96*sigma_u,3))`, `r tofr(round(1.96*sigma_u,3))`].

#### Partition de la variance

Un autre avantage net de l'effet aléatoire est l'estimation du paramètre $\sigma_{\upsilon}$, soit la variance au niveau des écoles. Ce dernier permet de calculer un indicateur très intéressant, soit l'**indice de corrélation intraclasse (ICC)** :

\footnotesize
\begin{equation}
ICC = \frac{\sigma_{\upsilon}}{\sigma_{\upsilon} + \sigma_{e}}
(\#eq:glmm3)
\end{equation}
\normalsize

Il s'agit donc du pourcentage de la variance présente au niveau des classes, qui peut être interprété comme le niveau de corrélation (de ressemblance) entre les élèves d'une même classe.

Dans notre cas, l'écart type est de `r tofr(round(sigma_u,3))` au niveau des classes et de `r tofr(round(sigma_e,3))` au niveau des élèves. Nous pouvons donc calculer l'ICC au niveau des classes avec la formule précédente : `r tofr(round(sigma_u,3))` / (`r tofr(round(sigma_u,3))` + `r tofr(round(sigma_e,3))`) = `r tofr(round(sigma_u /(sigma_u + sigma_e),3))`. Cela signifie que le niveau de corrélation entre deux élèves d'une même classe est de `r tofr(round(sigma_u /(sigma_u + sigma_e),3))` ou encore que `r tofr(round(sigma_u /(sigma_u + sigma_e),3)*100)`% de la variance de *Y* se situe au niveau des classes, ce qui est conséquent. Une telle information ne peut être extraite d'un modèle avec seulement des effets fixes. Notez ici que l'ICC peut être calculé pour chaque niveau d'un modèle à effet mixte. Dans notre exemple, nous n'avons qu'un seul niveau au-dessus des élèves, soit les classes, mais nous pourrions étendre cette logique à des écoles par exemple. Notez également que cette formule de l'ICC n'est valide que pour un modèle pour lequel la distribution de la variable *Y* est normale. Des développements apparaissent pour proposer d'autres formulations adaptées à d'autres distributions (imaginons le cas d'une distribution de Poisson n'ayant pas de paramètre de variance !), mais il est également possible d'estimer l'ICC à partir des simulations issues du modèle [@NakagawaICC ; @aly2014reliability ; @stryhn2006interpretation ; @wu2012comparison]. L'idée générale reste d'expliquer la partition de la variance dans le modèle.

En plus de l'ICC, il est également possible de calculer les **R^2^ marginal et conditionnel** du modèle. Le premier représente la variance expliquée par le modèle si seulement les effets fixes sont pris en compte, et le second si les effets fixes et aléatoires sont pris en compte. Distinguer les deux sources d'information permet de mieux cerner dans notre cas l'importance du rôle des écoles dans la performance des élèves. Dans notre cas, nous obtenons un R^2^ marginal de `r tofr(round(r2s[[1]],3))` et un R^2^ conditionnel de `r tofr(round(r2s[[2]],3))`, ce qui nous confirme à nouveau que le rôle joué par la classe dans le niveau de performance est loin d'être négligeable.

### GLMM avec pentes aléatoires

Dans cette seconde version du GLMM, nous n'envisageons plus de faire varier une constante en fonction des classes, mais un coefficient en fonction des classes. Admettons ici que nous voulions tester si l'effet du temps de travail ($x_1$) sur la performance scolaire (*Y*) n'est pas constant partout et que dans certaines classes, le temps de travail par semaine et dehors de l'école est plus efficace que d'autres. L'idée sous-jacente est que nous n'observons pas de différence en termes de moyenne entre deux classes, mais en termes d'effet pour notre variable $x_1$. À nouveau, nous pourrions nous contenter d'effet un fixe pour intégrer cette idée dans notre modèle. Pour cela, nous avons simplement à ajouter une interaction entre notre variable quantitative temps de travail et notre variable qualitative classe. Nous obtenons le résultat décrit par la figure \@ref(fig:randomslope). Notez ici que la constante est bien la même pour chaque classe (l'ensemble des lignes s'intersecte à 0 sur l'axe des x), et que seule la pente change.

```{r randomslope, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en interraction avec la classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + X:group, data = df3)
inter <- model$coefficients[[1]]
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- b1 + diffs

df4 <- data.frame(
  inter = inter,
  slope = diffs,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heures)", color = "Classe") + 
  xlim(0,max(df3$X)+1)
```

La formulation de ce modèle à effets fixes seulement est la suivante : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_j x_{2j} x_1}\\
&g(x) = x
\end{aligned}
(\#eq:glmm4)
\end{equation}
\normalsize

On constate donc que nous avons un effet principal $\beta_1$ décrivant le lien entre temps de travail et le score obtenu à l'examen pour l'ensemble des élèves, ainsi qu'un bonus ou un malus sur cet effet $\beta_j$ s'appliquant en fonction de la classe. Nous pouvons reformuler ce modèle pour inclure cet effet spécifique par classe comme un effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon x_1 \\
&\upsilon \sim Normal(0,\sigma_{\upsilon})\\
&g(x) = x
\end{aligned}
(\#eq:glmm5)
\end{equation}
\normalsize

Nous formulons ici un modèle dans lequel la classe modifie l'impact de la variable temps d'étude sur la variable note à l'examen. L'effet moyen de $x_1$ est capté par le coefficient $\beta_1$, les bonus ou malus ajoutés à cet effet par la classe sont issues d'une distribution normale centrée sur 0 avec un écart type, soit $\sigma_{\upsilon}$. À nouveau, l'idée est que si l'on moyennait l'effet de toutes les écoles, nous obtiendrions 0. Aussi, le fait de modéliser cet effet comme un effet aléatoire nous permet de partitionner la variance, de mutualiser l'information entre les classes et de resserrer l'estimation des effets des classes.

Les résultats pour ce second modèle sont présentés à la figure \@ref(fig:randomslope2), et une comparaison entre les estimations des effets fixes et des effets aléatoires est présentée à la figure \@ref(fig:randomslope3). Nous pouvons ainsi constater à nouveau l'effet de resserrement provoqué par l'effet aléatoire.


```{r randomslope2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en interraction avec la classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model2 <- lmer(Y2 ~ X + (-1+X|group), data = df3)
coeffs <- coef(model2)$group

df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heure)", color = "Classe") + 
  xlim(0,max(df3$X)+1)
```

```{r randomslope3, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en interraction avec la classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

df6 <- data.frame(
  fixed = df4$slope,
  random = df5$slope,
  group = df4$group
)

ggplot() + 
  geom_point(data = df4, mapping = aes(x = slope, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = slope, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$slope)) + 
  labs(x = "effet du temps de travail", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

rs2 <- r.squaredGLMM(model2)

```

Lorsque l'on intègre des pentes aléatoires dans un modèle, on fait face au problème suivant : la variance associée aux pentes aléatoires n'est pas fixe, mais proportionnelle à la variable *X* autorisée à varier. Si l'on compare la figure \@ref(fig:randominter3) (constantes aléatoires) et la figure \@ref(fig:randomslope2) (pentes aléatoires), on constate bien que la dispersion des prédictions du modèle (représentées par les lignes) augmente dans le cas de pentes aléatoires et reste identique dans le cas des constantes aléatoires. La conséquence pratique est qu'il existe potentiellement un nombre infini de valeurs possibles pour l'ICC. Dans ce contexte, il est préférable de laisser de côté cet indicateur et de ne reporter que les R^2^ marginal et conditionnel. Dans notre cas, nous obtenons les valeurs `r tofr(round(rs2[[1]],3))` et `r tofr(round(rs2[[2]],3))`, ce qui confirme une fois encore que le rôle joué par la classe est loin d'être négligeable puisqu'il permet d'expliquer près de `r tofr(round(rs2[[2]],3)*100)`% supplémentaire de variance comparativement aux seuls effets fixes expliquant `r tofr(round(rs2[[1]],3)*100)`% de la variance du score obtenu à l'examen.

### GLMM avec constantes et pentes aléatoires

Vous l'aurez certainement deviné en lisant le titre de cette section : il est tout à fait possible de combiner à la fois des constantes et des pentes aléatoires dans un modèle. Cela augmente bien sûr la complexité du modèle et introduit quelques subtilités comme la notion de distribution normale multivariée, mais chaque chose en son temps.

Si l'on reprend notre exemple avec nos élèves et nos classes, combiner à la fois des constantes et des pentes aléatoires revient à formuler l'hypothèse que chaque classe a un effet sur la moyenne de la performance de ses élèves, mais également un effet sur l'efficacité du temps de travail sur la performance. Il serait possible de créer un modèle avec uniquement des effets fixes tenant compte de ces deux aspects en ajoutant dans le modèle la variable multinomiale classe ainsi que son interaction avec la variable temps de travail. La formulation de ce modèle à effets fixes est la suivante :


\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_{2j}  x_{2j} + \beta_{3j} x_{2j}  x_1}\\
&g(x) = x
\end{aligned}
(\#eq:glmm6)
\end{equation}
\normalsize

Nous pouvons représenter les résultats de ce modèle avec la figure \@ref(fig:fullrandom1).

```{r fullrandom1, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe et de l'impact de la classe sur l'efficacité du temps de travail (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X*group, data = df3)
b1 <- model$coefficients[[2]]
inter <- model$coefficients[[1]]
inters <- c(0,model$coefficients[3:(2+length(colors)-1)])
coeffs <- c(0,model$coefficients[(2+length(colors)):length(model$coefficients)])

df4 <- data.frame(
  inter = inters + inter,
  slope = b1 + coeffs,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

Nous reformulons à présent ce modèle pour intégrer l'effet moyen de chaque classe (constante) et l'effet des classes sur l'efficacité du temps de travail (pente) comme deux effets aléatoires : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\left(\begin{array}{l}
\upsilon_{1} \\
\upsilon_{2}
\end{array}\right) \sim \mathcal{N}\left(\left(\begin{array}{l}
0 \\
0
\end{array}\right),\left(\begin{array}{cc}
\sigma_{\upsilon_1} & \sigma_{\upsilon_1\upsilon_2} \\
 \sigma_{\upsilon_1\upsilon_2} & \sigma_{\upsilon_1}
\end{array}\right)\right) \\
&g(x) = x
\end{aligned}
(\#eq:glmm7)
\end{equation}
\normalsize

Pas de panique ! Cette écriture peut être interprétée de la façon suivante.

Les modèles comprend deux effets aléatoires, l'un faisant varier la constante en fonction de la classe ($\upsilon_1$) et l'autre l'effet de la classe sur l'efficacité du temps de travail ($\upsilon_2$). Ces deux effets sont issus d'une distribution normale bivariée (une dimension par effet aléatoire). Cette distribution normale bivariée a donc deux moyennes et ces deux moyennes sont à 0 (les effets s'annulent si l'on considère ensemble toutes les classes). Elle dispose également d'une variance par effet aléatoire ($\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$) et d'une covariance entre les deux effets aléatoires ($\sigma_{\upsilon_1\upsilon_2}$). Cette covariance permet de tenir compte du fait que potentiellement, les écoles avec une constante plus élevée pourraient systématique avoir un effet plus élevé ou plus faible sur l'efficacité du temps de travail. Cette formulation implique donc d'ajuster trois paramètres de variance : $\sigma_{\upsilon_1}$, $\sigma_{\upsilon_2}$ et $\sigma_{\upsilon_1\upsilon_2}$. Il peut arriver que nous ne disposions pas d'assez de données pour estimer ces trois paramètres, ou que nous estimons pour des raisons théoriques qu'aucune corrélation ne soit attendue entre $\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$. Dans ce cas, il est possible de fixer $\sigma_{\upsilon_1\upsilon_2}$ à 0, ce qui revient à indiquer au modèle que  $\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$ proviennent de deux distributions normales distinctes, nous pouvons donc écrire :

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\left(\begin{array}{l}
\upsilon_{1} \\
\upsilon_{2}
\end{array}\right) \sim \mathcal{N}\left(\left(\begin{array}{l}
0 \\
0
\end{array}\right),\left(\begin{array}{cc}
\sigma_{\upsilon_1} & 0 \\
 0 & \sigma_{\upsilon_1}
\end{array}\right)\right) \\
&g(x) = x
\end{aligned}
(\#eq:glmm8)
\end{equation}
\normalsize

Ce qui est identique à : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\upsilon_{1} \sim Normal(0,\sigma_{\upsilon_1}) \\
&\upsilon_{2} \sim Normal(0,\sigma_{\upsilon_2}) \\
&g(x) = x
\end{aligned}
(\#eq:glmm9)
\end{equation}
\normalsize

Nous avons déjà abordé la notion de covariance dans la section \@ref(sect041). Pour rappel, la covariance dépend de l'unité de base des deux variables sur laquelle elle est calculée. Ici il s'agit d'un coefficient et d'une constante, on préfère donc généralement la standardiser pour obtenir la corrélation entre les deux effets : 

\footnotesize
\begin{equation}
corr(\upsilon_1;\upsilon_2) = \frac{\sigma_{\upsilon_1\upsilon_2}}{\sqrt{\sigma_{\upsilon_1}}\sqrt{\sigma_{\upsilon_2}}}
(\#eq:glmm10)
\end{equation}
\normalsize

Si cette corrélation est positive, cela signifierait dans notre cas que dans les classes ayant tendance à avoir un effet positif sur la performance scolaire ont tendance à également positivement influencer l'efficacité du temps de travail. À l'inverse, une corrélation négative signifierait que l'efficacité du temps de travail a tendance à être plus faible dans les classes où la performance scolaire moyenne est élevée. Si la corrélation n'est pas significative, c'est que les deux effets sont indépendants l'un de l'autre.

Pour cet exemple, nous conservons la première formulation afin de montrer comment interpréter $\sigma_{\upsilon_1\upsilon_2}$, mais nous ne disposons probablement pas de suffisamment de classes différentes pour estimer correctement ces trois paramètres. Les résultats de ce modèle sont représentés à la figure \@ref(fig:fullrandom2).

```{r fullrandom2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe et de l'impact de la classe sur l'efficacité du temps de travail (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

df3$x <- scale(df3$X,center = T, scale = T)

model2 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))
coeffs <- coef(model2)$group

df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")

covmod <- VarCorr(model2)$group[1,2]
sigma1 <- VarCorr(model2)$group[1,1]
sigma2 <- VarCorr(model2)$group[2,2]
```

Nous pouvons ainsi constater que pour ce troisième modèle, l'effet de resserrement est bien plus prononcé que pour les modèles précédents (\@ref(fig:fullrandom3)). Si l'on se fie au modèle à effets fixes (figure : \@ref(fig:fullrandom1)), alors l'impact de l'école sur l'efficacité du temps de travail est très important. En revanche, le modèle à effet aléatoire identifie que la différence de moyenne entre les écoles est importante, mais la différence en termes d'efficacité du temps de travail est beaucoup plus anecdotique.

```{r fullrandom3, echo=FALSE, fig.align='center', fig.cap="Comparaison des effets fixes et aléatoires pour le modèle intégrant l'effet des classes et l'interaction entre les classes et le tempsd de travail", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='90%'}
library(ggpubr)
plot1 <- ggplot() + 
  geom_point(data = df4, mapping = aes(x = inter, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = inter, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$inter)) + 
  labs(x = "constante", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

plot2 <- ggplot() + 
  geom_point(data = df4, mapping = aes(x = slope, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = slope, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$slope)) + 
  labs(x = "pente", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

ggarrange(plot1,plot2,ncol = 2, nrow = 1, common.legend = T)
rs2 <- r.squaredGLMM(model2)
```

Notre modèle estime les valeurs de $\sigma_{\upsilon_1}$ à `r tofr(round(sigma1, 3))`, de $\sigma_{\upsilon_2}$ à `r tofr(round(sigma2, 3))` et de $\sigma_{\upsilon_1\upsilon_2}$ à `r tofr(round(covmod, 3))`. La corrélation entre les deux effets est donc de `r tofr(round(covmod/(sqrt(sigma1)*sqrt(sigma2)), 3))` ce qui est relativement faible (pour l'anecdote, notez que la valeur originale de corrélation entre ces deux effets était de 0,1 lorsque nous avons simulé ces données, notre modèle est a donc bien été capable de retrouver le paramètre original). À nouveau, puisque nous avons des pentes aléatoires dans ce modèle, nous ne pouvons pas calculer l'ICC; nous pouvons cependant rapporter les R^2^ marginal et conditionnel. Leurs valeurs respectives sont `r tofr(round(r2s[[1]],3))` et `r tofr(round(r2s[[2]],3))`, ce qui nous confirme une nouvelle fois que l'ajout d'effets aléatoires contribue à expliquer une partie importante de la variance de la performance scolaire.

Pour terminer cette section, comparons brièvement les trois modèles (constantes aléatoires, pentes aléatoires, constantes et pentes aléatoires) pour déterminer lequel est le mieux ajusté à nos données. Nous ajoutons également un quatrième modèle dans lequel les deux effets aléatoires sont présents, mais non corrélés ($\sigma_{\upsilon_1\upsilon_2}=0$). Le tableau \@ref(tab:fullrandom4) nous permet de constater que l'ajout des constantes aléatoires joue un rôle essentiel dans le premier modèle : le R^2^ conditionnel est plus que deux fois supérieures au R^2^ marginal. Cependant, l'ajout des pentes aléatoires dans les trois autres modèles apporte finalement très peu d'information, nous laissant penser que l'effet de la classe sur le temps de travail est faible voire inexistant.


```{r fullrandom4, echo=FALSE, message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='90%'}
model1 <- lmer(Y2 ~ X + (1|group), data = df3)
model2 <- lmer(Y2 ~ X + (-1+X|group), data = df3)
model3 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))
model4 <- lmer(Y2 ~ X + (X||group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))

models <- list(model1,model2,model3,model4)

tableau <- data.frame(
  name = c("Constantes aléatoires", "Pentes aléatoires", "Pentes et constantes aléatoires corrélées", "Pentes et constantes aléatoires non-corrélées"),
  aic = round(sapply(models, function(i){AIC(i)}),1),
  r2m = round(sapply(models, function(i){r.squaredGLMM(i)[[1]]}),2),
  r2c = round(sapply(models, function(i){r.squaredGLMM(i)[[2]]}),2)
)

show_table(tableau,
          caption = 'Comparaison des trois modèles à effets aléatoires',
          col.names=c("modèle","AIC","R^2^ marginal","R^2^ conditionnel"),
          align= c("l","r", "r", "r"))

```

### Effet aléatoire avec design croisé ou imbriqué

::: {.bloc_aller_loin data-latex=""}
**Modèles à effets mixtes avec des structures croisées**

Jusqu'à présent, nous avons abordé des modèles GLMM comprenant des structures imbriquées (*nested* en anglais), c'est-à-dire qu'une observation d'un niveau 1 est incluse dans un et un seul groupe du niveau 2. Comme structure imbriquée à trois niveaux, nous avons vu comme exemple des élèves intégrés dans des classes elles-mêmes intégrées dans des écoles (figure \@ref(fig:glmmecoles)) : un élève appartient à une et une seule classe qui est elle-même localisée dans une et une seule école (élève / classe / école).

Notez qu'il est aussi possible d'avoir des structures des données croisées (*crossed*).

Admettons à présent que nous ne nous intéressons pas à la classe dans laquelle se situe l'élève, mais plutôt à son enseignant. Admettons également que les enseignants peuvent donner des cours dans plusieurs écoles. Nous nous retrouvons dans un cas de figure où un enseignant peut se situer dans plusieurs écoles, ce qui diffère du cas précédent où chaque classe appartient à une seule école. Dans ce second cas, on parle d'une **structure croisée** plutôt qu'imbriquée.

Si les professeurs enseignent dans toutes les écoles, il est possible de dire que le design d'étude est croisé complet ou croisé partiel si les professeurs n'enseignent que dans certaines écoles. La figure \@ref(fig:crossednested) résume graphiquement ces trois situations.


```{r crossednested, echo=FALSE, fig.align='center', fig.cap="Différentes structures de données hiérarchiques (imbriquée versus croisées)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='50%'}
knitr::include_graphics('images/glmm/glmm_croise-nested.png', dpi = NA)
```

Il est important de bien saisir la structure de son jeu de données, car l'estimation d'un modèle avec effets imbriqués ou croisés peut donner des résultats parfois significativement différents. De plus, un modèle imbriqué est généralement moins difficile à ajuster qu'un modèle croisé. En effet, dans un modèle imbriqué, deux élèves venant de deux écoles différentes sont jugés indépendants. Dans un modèle croisé, deux élèves provenant de deux écoles différentes peuvent tout de même partager une dépendance du fait qu'ils ont pu avoir le même professeur. La structure de dépendance (et donc de la matrice de covariance des effets aléatoires) est ainsi plus complexe pour un modèle croisé.

:::

## Conditions d'applicatoin des GLMM {#sect072}

Puisque les GLMM sont une extension des GLM, ils partagent l'essentiel des conditions d'application de ces derniers. Pour simplifier, si vous ajustez un modèle GLMM avec une distribution Gamma, vous devrez réaliser les mêmes tests que ceux pour un simple GLM avec distribution Gamma.

Une question importante se pose souvent lorsque l'on ajuste des modèles GLMM : **combien de groupes faut-il au minimum aux différents niveaux ?** En effet, pour estimer les différentes variances, nous devons disposer de suffisamment de groupes différents. Dans le cas d'un modèle avec uniquement une constante aléatoire, il est fréquent de lire que l'on doit disposer au minimum de cinq groupes différents [@gelman2006data], en dessous de ce minimum, traiter l'effet comme aléatoire plutôt que fixe apporte très peu d'information. De plus l'estimation des variances pour chaque niveau sera très imprécise donnant potentiellement des valeurs inexactes pour le ICC et polluant l'interprétation. Avec moins de groupes, il est certainement plus judicieux d'ajuster seulement un effet fixe. Dans un modèle avec plusieurs effets aléatoires et plusieurs variances / covariances à estimer, ce nombre doit être augmenté proportionnellement, à moins que les effets aléatoires ne soient estimés indépendants les uns des autres. Notez ici que si l'enjeu du modèle était d'estimer avec une grance précision les paramètres de variances, il faudrait compter au minimum une centaine de groupes.

Puisque les GLMM font intervenir la distribution normale aux niveaux supérieurs du modèle, il est nécessaire de vérifier si les hypothèses qu'elle implique sont respectées. Il s'agit essentiellement de deux hypothèses : les effets aléatoires suivent bien une distribution normale (univariée ou multivariée), et la variance au sein des groupes est bien homogène.

### Vérifier la distribution des effets aléatoires

Reprenons la formulation d'un modèle simple avec seulement deux niveaux et seulement une constante aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = x
\end{aligned}
\end{equation}
\normalsize

Ce modèle formule l'hypothèse que les constantes aléatoires $\upsilon$ proviennent d'une distribution normale avec une moyenne de 0 et un écart type $\sigma_{\upsilon}$. La première étape du diagnostic est donc de vérifier si les constantes aléatoires suivent bien une distribution normale, ce que l'on peut faire habituellement avec un diagramme quantile-quantile. Si nous reprenons notre exemple avec nos données de performance scolaire des sections précédentes, nous obtenons la figure \@ref(fig:diagglmm1). Puisque les points tombent bien approximativement sur la ligne rouge, nous pouvons conclure que cette condition d'application est bien respectée. Notez qu'il est également possible d'utiliser ici un des tests vus dans le chapitre \@ref(chap02) pour tester formellement la distribution des constantes aléatoires, mais nous disposons rarement de suffisamment de valeurs différentes.

```{r diagglmm1, echo = FALSE, fig.align='center', fig.cap="Distribution normale univariée des constantes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
model2 <- lmer(Y2 ~ X + (1|group), data = df3)

qplot(sample = ranef(model2)$group[,1])+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(title="Diagramme quantile-quantile",
     x="Valeurs théoriques",
     y = "Constantes aléatoires")
```

Cette vérification est bien-sûr à appliquer à chacun des niveaux (en dehors du niveau de base) du modèle étudié.

Si nous nous intéressons maintenant au modèle avec constantes et pentes aléatoires, nous avons deux cas de figure :

* notre modèle inclut une covariance entre les constantes et les pentes ; elles proviennent donc d'une distribution normale bivariée.

* notre modèle considère que les pentes et les constantes comme indépendantes; elles proviennent donc de deux distributions normales distinctes.

Le second cas est de loin le plus simple puisqu'il nous suffit simplement de réaliser un graphique de type Quantile-Quantile pour les deux effets aléatoires séparément. Dans le premier cas, il nous faut adapter notre stratégie pour vérifier si les deux effets aléatoires suivent conjointement une distribution normale multivariée. Pour cela, nous devons dans un premier temps observer séparément la distribution des pentes et des constantes puisque  chaque variable provenant d'une distribution normale multivariée suit elle-même une distribution normale univariée  [@burdenski2000evaluating]. Nous pouvons dans un second temps construire un graphique nous permettant de juger si nos pentes et constantes suivent bien la distribution normale bivariée attendue par le modèle. Pour l'illustrer, nous reprenons le modèle sur la performance scolaire intégrant des pentes et des constantes aléatoires avec une covariance estimée entre les deux.

La figure \@ref(fig:diagglmm2) représente donc les deux graphiques Quantile-Quantile univariés. Les deux semblent indiquer que nos effets aléatoires suivent bien chacun une distribution normale. La figure \@ref(fig:diagglmm3) montre la distribution normale bivariée attendue par le modèle avec des ellipses représentant différents pourcentiles de cette distribution. Les valeurs des effets aléatoires  sont représentés par des points noirs. Seulement 5% des points noirs devraient se trouver dans la première ellipse et 95% des points devraient se trouver dans la quatrième ellipse. En revanche, seulement 20% des points devraient se trouver dans le dernier anneau et seulement 5% des points en dehors de cet anneau. Il faut donc évaluer si les points sont plus ou moins centrés que ce que l'on attend. Pour simplifier la lecture, il est possible de rajouter des points grisés en arrière plan représentant des réalisations possibles  de cette distribution normale bivariée. Les vrais points noirs devraient avoir une dispersion similaire à celle des points grisés. Dans notre cas, ils semblent suivre un patron cohérent avec notre distribution normale bivariée. Dans le cas contraire, cela signifierait que le modèle doit être révisé.

```{r diagglmm2, echo = FALSE, fig.align='center', fig.cap="Multiples distributions normales univariées des constantes et pentes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
model2 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))

re_effects <- ranef(model2)$group

q1 <- qplot(sample = re_effects[,1])+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(x="Valeurs théoriques",
     y = "Constantes aléatoires")

q2 <- qplot(sample = re_effects[,2])+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(x="Valeurs théoriques",
     y = "Pentes aléatoires")

ggarrange(q1,q2)
```


```{r diagglmm3, echo = FALSE, fig.align='center', fig.cap="Distribution normale bivariée des constantes et pentes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
cor_mat <- VarCorr(model2)[[1]]

re_effects <- data.frame(ranef(model2)$group)
names(re_effects) <- c("constante","pente")

library(ellipse)

levels <- c(0.05,0.25,0.75,0.95)

els <- lapply(levels, function(i){
  el <- data.frame(ellipse(cor_mat,center = c(0,0), level = i))
  names(el) <- c("x","y")
  return(el)
})

ref_points <- data.frame(data.frame(MASS::mvrnorm(n = 1000, mu = c(0,0), Sigma = cor_mat)))
names(ref_points) <- c("x","y")

ggplot() + 
  geom_point(aes(x = x, y = y), data = ref_points, alpha = 0.3, size = 0.4) + 
  geom_path(data = els[[1]], aes(x = x, y = y, color = "a")) + 
  geom_path(data = els[[2]], aes(x = x, y = y, color = "b")) + 
  geom_path(data = els[[3]], aes(x = x, y = y, color = "c")) +
  geom_path(data = els[[4]], aes(x = x, y = y, color = "d")) + 
  geom_point(data = re_effects, aes(x = constante, y = pente))+
  scale_color_manual(values = c("a"="#90e0ef",
                                "b"="#00b4d8",
                                "c"="#0077b6",
                                "d"="#03045e"),
                     labels = c("5%","25%","75%","95%"))

```

### Homogénéité des variances au sein des groupes

Dans le chapitre \@ref(chap06) sur les GLM  nous avons vu que chaque distribution a sa propre définition de la variance. Pour rappel, un modèle gaussien assume une variance constante, un modèle de Poisson assume une variance égale à son espérance, alors qu'un modèle Gamma assume une variance proportionnelle au carré de son espérance divisée par un paramètre de forme, etc. Nous devions donc pour chaque GLM vérifier graphiquement si la variance présente dans les données originales était proche de la variance attendue par le modèle. Dans un modèle GLMM, le même exercice doit être fait pour chaque groupe aux différents niveaux du modèle. 

À titre d'exemple, dans notre exemple sur la performance scolaire, notre variable *Y* a été modélisée avec une distribution normale. Le modèle assume donc une uniformité de sa variance (homoscédasticité). La figure \@ref(fig:glmmvariance) nous montre ainsi qu'elle que soit la classe, la dispersion des points semble bien respecter la variance attendue par le modèle (représentée par les lignes noires).


```{r glmmvariance, echo=FALSE, fig.align='center', fig.cap="Homogénéité de la variance pour les différents groupes d'un modèle GLMM Gaussien", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='95%'}
library(lme4)

model2 <- lmer(Y2 ~ X + (1|group), data = df3)

# Extraction des prédictions du modèle
mus <- predict(model2, type = "response")
sigma_model <- sigma(model2)

# Création d'un dataframe pour contenir les prédictions et les vraies valeurs
df1 <- data.frame(
  mus = mus,
  reals = df3$Y2,
  group = df3$group
)

df1$group <- as.factor(df1$group)

# Calcul de l'intervalle de confiance à 95% selon la distribution normale
# et stockage dans un second dataframe
seqa <- seq(70,95,5)
df2 <- data.frame(
  mus = seqa,
  lower = qnorm(p = 0.025, mean = seqa, sd = sigma_model),
  upper = qnorm(p = 0.975, mean = seqa, sd = sigma_model)
)

# Affichage des valeurs réelles et prédites (en rouge)
# et de leur variance selon le modèle (en noir)
ggplot() + 
  geom_point(data = df1, 
             mapping = aes(x = mus, y = reals),
             color ="red", size = 0.5) + 
  geom_errorbar(data = df2,
                mapping = aes(x = mus, ymin = lower, ymax = upper),
                width = 0.2, color = rgb(0.4,0.4,0.4)) + 
  labs(x = 'valeurs prédites',
       y = "valeurs réelles") + 
  facet_wrap(vars(group), ncol=3)

```

## Inférence dans les modèles GLMM

Une des questions importantes que l'on se pose lorsque l'on construit un modèle est toujours : est-ce que les différents effets présents dans le modèle ont un impact significativement différent de zéro sur la variable dépendante ? Cette étape d'inférence est plus compliquée pour les modèles GLMM que dans les modèles GLM à cause de la présence d'effets aléatoires. Ces derniers brouillent le comptage du nombre de paramètres et par extension du nombre de degrés de liberté des modèles. Pour un effet aléatoire, il est possible de déterminer que le nombre de degrés de liberté est de 1 puisque nous ajustons un seul paramètre supplémentaire (la variance de cet effet aléatoire). Selon un autre point de vue, il serait possible d'affirmer que le nombre de degrés de liberté est de k-1 (avec k le nombre de groupes dans cet effet aléatoire), ce que nous utilisons habituellement pour un effet fixe. La vrai valeur du nombre de degrés de liberté se situe quelque part entre ces deux extrèmes. L'enjeu du nombre de degrés de liberté est crucial, car il impacte directement l'estimation des valeurs de *P* pour l'ensemble des coefficients du modèle. Avec un nombre de degrés de liberté plus petit, les valeurs de *P* seront plus faibles et les effets "plus significatifs". Le sujet est d'ailleurs l'objet d'une telle controverse que les auteurs de certains *package* comme **lme4** (un des *packages* les plus utilisés pour ajuster des GLMM) ont fait le choix de ne renvoyer aucune valeur de *P* dans les résultats des modèles. L'article de @bolker2009generalized propose une explication détaillée et relativement accessible du problème (en plus d'une excellente introduction aux GLMM), en se basant sur leurs recommandations, il est possible de séparer le problème de l'inférence dans les GLMM en trois sous problèmes : 

* Quel est le degré de significativité des effets fixes ?
* Quel est le degré de significativité général de l'effet aléatoire dans le modèle ?
* Quels sont les degrés de significativité de chaque constante / pente aléatoires ?


### Inférence pour les effets fixes

Trois approches peuvent être envisagées pour déterminer si un effet fixe est significatif ou non. Elles font appel à trois approches théoriques différentes (test classique, comparaison de modèles et bootstrapping) et peuvent donc donner des résultats différents. À titre exploratoire, il peut être intéressant de toutes les tester, mais certaines peuvent être préférées en fonction de votre champ de recherche.

#### Test classique

Nous avions vu pour les modèles LM et GLM que les valeurs de *P* étaient calculées à partir de scores obtenus en divisant le coefficient par son erreur standard. Une approche similaire peut être utilisée pour les modèles GLMM. Cependant, la question du nombre de degrés de liberté à utiliser comme dénominateur reste un problème. L'approche la plus flexible est certainement l'approximation par la méthode Satterthwaite proposant une estimation de ce nombre de degré de liberté et par extension des valeurs de *P*.

#### Rapports de vraisemblance

Si le modèle comprend suffisamment d'observations (par suffisamment comprenez au moins une centaine d'observations par paramètre), il est également possible d'utiliser une série de tests de rapport de vraisemblance pour vérifier si l'apport de chaque variable indépendante contribue à améliorer significativement le modèle. Cette approche correspond à une analyse de type trois comme nous l'avions mentionné dans la section \@ref(sect06214) pour le modèle logistique multinomial.

#### Bootstrapping

L'approche par *Bootstrapping* (*parametric-bootstrap* ou *semi-parametric-bootstrap*) permet de calculer pour les différents paramètres d'un modèle un intervalle de confiance. L'idée étant de réajuster un grand nombre de fois le modèle sur des sous-échantillons des données pour saisir la variabilité des différents paramètres du modèle. Si les intervalles de confiance ainsi construits ne comprennent pas zéro, il est possible de dire que cet effet est significatif. À nouveau, cette méthode n'est valide que si le jeu de données comporte suffisamment d'observations. L'intérêt de cette approche est qu'elle ne postule pas d'hypothèse sur la distribution des paramètres qui ont la fâcheuse tendance à ne pas suivre une distribution normale dans le cas des GLMM. Elle est d'ailleurs considérée comme la plus robuste bien que coûteuse en termes de temps de calcul.

### Inférence pour les effets aléatoires, impact global

Pour déterminer si un effet aléatoire a un impact significatif dans un modèle, il est recommandé d'utiliser un test de rapport de vraisemblance entre un modèle sans l'effet aléatoire et un modèle avec l'effet aléatoire. L'analyse des différences entre les valeurs de déviance, AIC et BIC peut également aider à déterminer si l'ajout de l'effet aléatoire est justifié. Il est également possible de considérer les valeurs du ICC et du R^2^ conditionnel. Notez ici que si vous avez une très bonne raison théorique d'ajouter l'effet aléatoire dans votre modèle et suffisamment d'observations / groupes pour l'ajuster, il peut être pertinent de laisser l'effet aléatoire dans le modèle même si tous les indicateurs mentionnés précédemment indiquent qu'il contribue faiblement au modèle. Le retirer risquerait en effet de donner l'impression que les autres paramètres du modèle sont plus significatifs qu'ils ne le sont en réalité.

Notez que l'approche par Bootstrapping décrite pour les effets fixes peut aussi être utilisées ici pour obtenir un intervalle de confiance pour l'ICC, le R^2^ conditionnel et les différents paramètres de variance et co-variance. 

### Inférence pour les effets aléatoires, constantes et pentes

Pour rappel, dans l'approche fréquentiste présentée ici, les valeurs des constantes et des pentes aléatoires ne sont pas à proprement parler des paramètres du modèle : elles sont estimées à posteriori (BLUP). Pour déterminer si ces constantes et pentes sont significativement différentes de zéro et significativement différentes les unes des autres, il est possible de calculer les intervalles de confiance de chacune d'entre elles par Bootstrap, par profilage ou par simulation à partir du modèle. Si la constante du groupe *j* a zéro dans son intervalle de confiance, on peut alors déclarer que le groupe *j* en question ne semble pas varier du reste de la population en termes de moyenne. Si la pente *l* du groupe *j* a zéro dans son intervalle de confiance, on peut alors déclarer que le groupe *j* en question ne semble pas varier du reste de la population pour l'effet *l*. Notez que la méthode par simulation est bien plus rapide que les deux autres, mais que l'approche par bootstrap reste la plus fiable.

## conclusion sur les GLMM

Les GLMM sont donc une extension des GLM nous offrant une grande flexibilité de modélisation (variabilité des pentes et des constantes en fonction de groupes) et nous permettant d'analyser la partition de la variance entre plusieurs niveaux présents dans nos données. Cependant, cette flexibilité implique des modèles plus complexes avec un travail de diagnostic et d'interprétation plus long et potentiellement plus ardu.


## GLMM : application dans R {#sect073}

Pour cet exemple de GLMM, nous proposons de réanalyser les données présentées dans la section \@ref(sect06211) sur le modèle logistique binomial. Pour rappel, nous modélisions la probabilité qu'un individu utilise le vélo comme mode de transport pour son trajet le plus fréquent en utilisant une enquête réalisée auprès de près de 26000 européens. Initialement, nous avions intégré les pays comme un effet fixe, or nous savons à présent qu'il serait plus judicieux de les traiter comme un effet aléatoire. Nous comparons deux modèles, un pour lequel seulement la constante varie par pays et un second dans lequel la pente pour l'âge varie également par pays. L'hypothèse étant que dans certain pays, l'impact de l'âge sur l'utilisation du vélo pourrait être réduit dans certains pays ou la culture du vélo est plus présente. Cette hypothèse implique également la présence potentielle d'une corrélation inverse entre la constante et la pente de chaque pays : un pays avec une probabilité plus élevé de base d'utiliser la vélo a probablement un impact réduit sur l'effet de l'âge.

Pour ajuster ces modèles, nous utilisons le *package* **lme4**, permettant d'ajuster des modèles GLMM avec des distribution gaussienne, gamma, poisson et binomial. Lorsque d'autres distributions sont nécessaires, il est possible de se tourner vers le *package* **gamlss**. Notez cependant que les effets aléatoires de **gamlss** sont estimés avec une méthode appelée PQL très flexible mais qui peut produire des résultats erronés dans certains cas [@bolker2009generalized].

Afin de limiter les répétitions, nous ne recalculons pas ici le VIF et nous excluons d'emblée les observations aberrante (provenant de Malte, Chypre ou avec des temps de trajets supérieurs à 400 minutes).

### Ajustement du modèle avec uniquement une constante aléatoire

Nous commençons donc par ajuster un premier modèle avec une constante aléatoire en fonction du Pays. Dans la plupart des *packages* intégrant des effets aléatoires, la syntaxe suivante est utilisée pour stipuler une constante aléatoire : `+ (1|Pays)`. Concrètement, nous tentons d'ajuster le modèle décrit par l'équation \@ref(eq:glmmbinom1)

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Binomial(p)\\
&g(p) = \beta_0 + \beta_1 x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = log(\frac{x}{1-x})
\end{aligned}
(\#eq:glmmbinom1)
\end{equation}
\normalsize

Il s'agit simplement d'un modèle logistique binomial dans lequel nous avons rajouter une constante aléatoire : $\upsilon$. Dans notre cas, elle varie pas Pays. La syntaxe dans R pour produire ce modèle est la suivante.

```{r message=FALSE, warning=FALSE, out.width='50%'}
# Chargement des données
dfenquete <- read.csv("data/glm/enquete_transport_UE.csv")
dfenquete$Pays <- relevel(as.factor(dfenquete$Pays), ref = "Germany")

# Retirer les observations aberrantes
dfenquete2 <- subset(dfenquete, (dfenquete$Pays %in% c("Malta", "Cyprus")) == F & 
                  dfenquete$Duree < 400)

# Ajustement du modèle
library(lme4)

# necessité ici de centrer réduire ces variables pour permettre au modèle de converger
dfenquete2$Age2 <- scale(dfenquete2$Age,center = T, scale = T)
dfenquete2$Duree2 <- scale(dfenquete2$Duree,center = T, scale = T)

modele1 <- glmer(y ~Sexe + Age2 + Education + StatutEmploi + Revenu +
              Residence + Duree2 + ConsEnv + (1|Pays),
            family = binomial(link="logit"),
            control = glmerControl(optimizer = "bobyqa"),
            data = dfenquete2)
```

Nous réaliserons l'ensemble des diagnostic dans une section dédiée en fin de chapitre, nous nous concentrons ici sur l'interprétation des résultats du modèle. Notez cependant que le diagnostic devrait **précéder** l'interprétation comme nous l'avons vu dans la section sur les modèles GLM.

Vous noterez ici que nous avons centré-réduit les variables `Age` et `Duree`. Il est souvent nécessaire de réaliser cette étape en amont pour s'assurer que le modèle converge sans trop de difficulté. Dans notre cas, si ces deux variables sont laissées dans leur échelle d'origine, la fonction `glmer` ne parvient pas à trouver de solution. Notez que cette transformation n'affecte que la valeur relative de leurs coefficients respectifs.

La fonction `summary` nous donne accès à un premier ensemble d'informations

```{r message=FALSE, warning=FALSE, out.width='50%'}
summary(modele1)
```

La première partie de ce résumé nous rappelle la formule utilisée pour le modèle et nous indique différent indicateurs de qualité d'ajustement comme le AIC, le BIC et la déviance. Nous avons ensuite une partie dédiée aux effets aléatoires (`Random Effects`) et une partie dédiée aux effets fixes (`Fixed effects`). Cette dernière s'interprète de la même manière que pour un modèle à effet fixe, n'oubliez cependant pas d'utiliser la fonction exponentielle pour obtenir les rapports de cotes (fonction de lien logistique).

#### Rôle joué par l'effet aléatoire

Comme vous pouvez le constater, la section `Random Effects` ne comprend qu'un seul paramètre : la variance de l'effet pays. Nous pouvons ainsi écrire que l'effet du pays suit une distribution normale avec une moyenne de 0 et une variance $\sigma^2$ de `r tofr(round(VarCorr(modele1)[[1]][[1]],3))`. Pour aller plus loin dans cet analyse, nous pouvons calculer le coefficient de corrélation intraclasse (ICC). Cependant, puisque notre modèle est binomial et non gaussien, nous ne disposons pas d'une variance au niveau des individus, il est donc possible à la place d'utiliser la variance théorique du modèle : $\frac{\pi^2}{3}$. Nous calculons ainsi notre ICC : 

```{r message=FALSE, warning=FALSE, out.width='50%'}
# extraction de la variance des Pays
var_pays <- VarCorr(modele1)[[1]][[1]]

# calcul de l'ICC
var_pays / (((pi**2)/3) + var_pays)
```

Nous pouvons parvenir au même résultat en utilisant la fonction `icc` du *package* **performance**.

```{r message=FALSE, warning=FALSE, out.width='50%'}
library(performance)

# calcul de l'ICC
icc(modele1)
```

Notez que cette fonction distingue un ICC ajusté et un ICC conditionnel. Le premier correspond à l'ICC que nous avons présenté jusqu'ici et que nous avons calculé à la main. L'ICC conditionnel inclue dans son estimation la variance présente dans les effets fixes. Un fort écart entre ces deux ICC indiquerait que les effets fixes sont capables de capturer une très forte variance dans les données ce qui pourrait remettre en cause la pertinence de l'effet aléatoire. Dans notre cas, la différence entre les deux est très faible.

En plus du ICC, nous pouvons calculer les R^2^ marginal et conditionnel. Pour cela, nous devons faire appel au *package* **MuMIn**.

```{r message=FALSE, warning=FALSE, out.width='50%'}
library(MuMIn)
r.squaredGLMM(modele1)
```

Dans notre cas, la fonction nous renvoie  la fois les R^2^ obtenu en utilisant la variance théorique du modèle ($\frac{\pi^2}{3}$ dans notre cas) et la variance estimée par la méthode delta. La seconde est plus conservative dans ce cas, mais les deux résultats indiquent que les effets aléatoires expliquent une part importante de la variance comparativement aux effets fixes. Notez également que la fonction `r2` du *package* **performance** peut calculer ces deux R^2^, mais seulement en utilisant la variance théorique.

#### significativité de l'effet aléatoire

Nous souhaitons déterminer ici si notre effet aléatoire contribue à significativement améliorer le modèle. Pour cela, nous effectuons un test de rapport de vraisemblance entre le modèle sans l'effet aléatoire (un simple GLM ici) et le modèle complet. Nous utilisons pour cela la fonction `anova` : 

```{r message=FALSE, warning=FALSE, out.width='50%'}
# ajustement d'un modèle sans l'effet aléatoire
model_simple <- glm(y ~Sexe + Age2 + Education + StatutEmploi + Revenu +
              Residence + Duree2 + ConsEnv,
            family = binomial(link="logit"),
            data = dfenquete2)

# comparaison des deux modèles
anova(modele1,model_simple)
```

Le test indique clairement que le modèle complet est mieux ajusté. Le AIC, le BIC et la déviance sont tous grandement réduits et le test est largement significatif.

Pour aller plus loin, nous pouvons utiliser une approche Bootstrap pour calculer un intervalle de confiance pour la variance de l'effet aléatoire, le ICC et le R^2^ conditionnel. Nous utilisons pour cela la fonction `bootMer`. Si vous essayez de lancer cette syntaxe, vous constaterez qu'elle prend énormément de temps, ce qui s'explique par le grand nombre de fois ou le modèle doit être réajusté. Nous vous recommandons donc de bien enregistrer vos résultats après l'exécution de la fonction avec la fonction `save.` Notez que pour réduire significativement le temps de calcul, il est possible d'utiliser simultanément plusieurs coeurs de votre processeur, ce que nous faisons ici avec le *package* **snow**.

```{r message=FALSE, warning=FALSE, out.width='50%', eval=F, echo=T}
# definition d'une fonction pour extraire les valeurs qui nous intéresse
extractor <- function(mod){
  vari <- VarCorr(mod)[[1]][[1]]
  ICC <- vari / (vari + (pi**2/3))
  r2cond <- performance::r2(mod)[[1]]
  return(c("vari"=vari,"icc"=ICC,"r2cond"=r2cond))
}

# préparation d'un environnement multiprocessing pour accéler le calcul
library(snow)

# préparation de 8 coeurs (attention si votre machine en a moins !)
cl <- makeCluster(8)
clusterEvalQ(cl,library("lme4"))
valeurs <- bootMer(modele1,FUN = extractor,nsim = 1000,
                   use.u = F, type="parametric", ncpus = 8,
                   parallel="snow",
                   cl = cl)

# sauvegarde des résultats
save(valeurs,file = 'data/glmm/boot_binom.rda')
```

Nous pouvons à présenter analyser l'incertitude de ces différents paramètres. Pour cela nous devons commencer par observer graphiquement leurs distributions obtenues par bootstrap avec la figure \@ref(fig:bottdistrib).

```{r bottdistrib, message=FALSE, warning=FALSE, out.width='80%',echo=T, fig.cap = "Distributions obtenues par Bootstrap de la variance, l'ICC et le R^2^ conditionnel"}
# chargement de nos valeurs préalablement enregistrées
load('data/glmm/boot_binom.rda')

# construction de trois graphiques de distributions
df <- data.frame(valeurs$t)
names(df) <- c("variance","icc","R2cond")

breaks1 <- as.vector(quantile(df$variance, probs = c(0.001,0.15,0.5,0.85, 0.999)))
labs1 <- round(breaks1,2)
p1 <- ggplot(df) + 
  geom_histogram(aes(x = variance), bins = 50, fill = "#e63946", color = "black")+
  geom_vline(xintercept = median(df$variance),
             color = "black", linetype="dashed", size = 1)+
  scale_x_continuous(breaks = breaks1, labels = labs1)+
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank(), axis.title.y = element_blank())

breaks2 <- as.vector(quantile(df$icc, probs = c(0.001,0.15,0.5,0.85, 0.999)))
labs2 <- round(breaks2,2)
p2 <- ggplot(df) + 
  geom_histogram(aes(x = icc), bins = 50, fill = "#a8dadc", color = "black")+
  geom_vline(xintercept = median(df$icc),
             color = "black", linetype="dashed", size = 1)+
  scale_x_continuous(breaks = breaks2, labels = labs2)+
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank(), axis.title.y = element_blank())


breaks3 <- as.vector(quantile(df$R2cond, probs = c(0.001,0.15,0.5,0.85, 0.999)))
labs3 <- round(breaks3,3)
p3 <- ggplot(df) + 
  geom_histogram(aes(x = R2cond), bins = 50, fill = "#1d3557", color = "black")+
  geom_vline(xintercept = median(df$R2cond),
             color = "black", linetype="dashed", size = 1)+
  scale_x_continuous(breaks = breaks3, labels = labs3)+
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank(), axis.title.y = element_blank())

ggarrange(p1,p2,p3, nrow = 2, ncol = 2)
```

Les trois distributions sont toutes suffisamment éloignées de zéros pour que l'on puisse en conclure que ces différentes valeurs sont toutes différentes de zéro. Notez également que les distributions sont relativement symétriques, indiquant que nous disposons de probablement suffisamment d'information dans nos données pour inclure notre effet aléatoires. Des distributions fortement asymétriques auraient indiqués au contraire une forte difficulté du modèle à estimer le paramètre de variance à partir des données. Dans un article, il n'est pas nécessaire de reporter ce graphiques, mais plus simplement les intervales de confiance à 95% et les médianes : 

```{r}
#intervale de confiance pour la variance
quantile(df$variance,probs = c(0.0275,0.5,0.975))

#intervale de confiance pour l'ICC
quantile(df$icc,probs = c(0.0275,0.5,0.975))

#intervale de confiance pour le R2 conditionnel
quantile(df$R2cond,probs = c(0.0275,0.5,0.975))
```
 

#### significativité des différentes constantes

Puisque nous avons conclu que l'effet aléatoire contribue significativement au modèle, nous pouvons à présent observer si les constantes ajustées pour chaque pays varient significativement les unes des autres. Pour rappel, les pentes et les constantes aléatoires ne sont pas directement estimées par le modèle, mais à postériori. La conséquence de cela est que nous ne disposons pas d'un moyen directe de mesurer l'incertitude de ces paramètres et donc de construire des intervalles de confiances. Une première option pour contourner ce problèmes est d'effecter des simulations à partir à partir de la distribution postérieur du modèle. Notez que cette approche s'inspire largement de l'approche statistique bayésienne. Nous utilisons ici le *package* **merTools** pour effecter 1000 simulations et obtenir une erreur standard pour chaque constante aléatoire de chaque pays.

```{r randomconstantes1, message=FALSE, warning=FALSE, out.width='70%',echo=T, fig.cap = "Constantes aléatoires estimées par Pays (IC par simulations)"}
# Simulations et extraction des effets aléatoires
library(merTools)
simsRE <- REsim(modele1,n.sims = 1000, oddsRatio = F)

# calcul des intervalles de confiance
simsRE$lower <- simsRE$mean - 1.96 * simsRE$sd
simsRE$upper <- simsRE$mean + 1.96 * simsRE$sd

# variable binaire pour la significativité
simsRE$sign <- case_when(
  simsRE$lower<0 & simsRE$upper<0 ~ "inf",
  simsRE$lower>0 & simsRE$upper>0 ~ "sup",
  TRUE ~ "not"
)

# représentation des intervalles de confiance
ggplot(simsRE) + 
  geom_errorbarh(aes(xmin = lower, xmax = upper,
                     y = reorder(groupID,mean)), size = 0.5, height = 0.5) + 
  geom_point(aes(x = mean, y = reorder(groupID,mean),
                 color = sign)) + 
  scale_color_manual(values = c("inf" = "#0077b6", "sup" = "#e63946", "not"="#000000"), labels = c("sign. < 0", "non sign.", "sign. > 0")) +
  labs(x = "Constante aléatoire", y = "Pays")
```

La figure \@ref(fig:randomconstantes1) permet de repérer en un coup d'oeil les pays pour lesquels la probabilité d'utiliser le vélo comme moyen de transport pour le trajet le plus fréquent est la plus élevée ou la plus faible. Notez cependant que les valeurs représentées sont pour l'instant des logarithme de rapport de cotes. Nous devons donc les convertir en rapport de cote avec la fonction exponentiel pour faciliter leur interprétation.

```{r}
# convertion en rapport de cote (et arrondi à trois décimales)
mat <- round(exp(simsRE[c("mean","lower","upper")]),3)
rownames(mat) <- simsRE$groupID
names(mat) <- c("RC","RC.025","RC.975")
print(mat)
```

Nous observons ainsi qu'une personne vivant en Finlande voit ses chances multipliées par 2,25 d'utiliser le vélo comme mode de transport pour son trajet le plus fréquent comparativement à la moyenne des pays européens. À l'inverse, une personne résident en France a 47% de chance de moins d'utiliser le vélo.

Notez cependant que cette approche basée sur des simulations peut poser des problèmes car elle ne renvoie qu'une erreur standard pour mesurer l'incertitude de nos constantes. Dans les cas où nous ne disposons pas de beaucoup d'observation par groupe, la distribution à postériori des constantes peut être asymétrique, rendant l'estimation des intervalles de confiance par le erreurs standards inutiles. Il est possible de détecter ce cas de figure quand les médianes et les moyennes renvoyées par la fonction `simsRE` diffèrent nettement. Une alternative plus robuste est à nouveau d'estimer la variabilité des effets aléatoires par bootstrap. Cette méthode requiert bien plus de temps de calcul que la précédentes, nous vous recommandons donc de commencer par la méthode par simulation pour disposer d'un premier aperçu des résultats et ensuite la méthode bootstrap quand votre modèle est dans sa forme final.

```{r, eval = FALSE, echo = TRUE}
# créations de la fonction d'extraction
extractor2 <- function(mod){
  elements <- ranef(mod)$Pays
  vec <- elements[,1]
  names(vec) <- rownames(elements)
  return(vec)
}

# preparation de l'operation en multiprocessing
cl <- makeCluster(8)
clusterEvalQ(cl,library("lme4"))

# calcul des effets aléatoires en bootstrap
valeurs <- bootMer(modele1,FUN = extractor2,nsim = 1000,
                   use.u = T, type="parametric", ncpus = 8,
                   parallel="snow",
                   cl = cl)

# sauvegarder des résultats !
save(valeurs,file = 'data/glmm/boot_binom2.rda')
```

Puisque nous disposons des distributions bootstrapées des différents effets aléatoires, nous pouvons directement les représentées dans un graphique avec la figure \@ref(fig:randomconstantes2). Les résultats sont très similaires à ceux de la figure \@ref(fig:randomconstantes1), ce qui s'explique par le grand nombre d'observation et de groupes. Avec moins d'observations, il est recommandé de privilégier l'approche par bootstrap.

```{r randomconstantes2, message=FALSE, warning=FALSE, out.width='70%',echo=T, fig.cap = "Constantes aléatoires estimées par Pays (IC par bootstrap)", fig.align="center"}

# chargement de nos valeurs bootstrapées
load('data/glmm/boot_binom2.rda')

# conversion des bootstraps en intervals de confiance
q025 <- function(x){return(quantile(x,probs = 0.025))}
q975 <- function(x){return(quantile(x,probs = 0.975))}

df <- reshape2::melt(valeurs$t)
df_med <- df %>% group_by(Var2) %>% summarise(
  med = median(value),
  lower = q025(value),
  upper = q975(value))

# ajout d'une variable pour la couleur si significatif
df_med$sign <- case_when(
  df_med$lower<0 & df_med$upper<0 ~ "inf",
  df_med$lower>0 & df_med$upper>0 ~ "sup",
  TRUE ~ "not"
)

# Affichage des résultats
ggplot(df_med) + 
  geom_errorbar(aes(xmin = lower, xmax = upper, y = reorder(Var2,med)), width = 0.5) +
  geom_point(aes(x = med, y = reorder(Var2,med), color = sign)) + 
  scale_color_manual(values = c("inf" = "#0077b6", "sup" = "#e63946", "not"="#000000"), labels = c("sign. < 0", "non sign.", "sign. > 0")) +
  labs(x = "Constante aléatoire", y = "Pays")

```

### Ajustement du modèle avec constantes et pentes aléatoires

Dans le modèle précédent, nous avons ajusté pour chaque pays une constante aléatoire afin de vérifier si la probabilité d'utiliser le vélo comme mode de transport principal changeait d'un Pays de l'Europe à l'autre. Nous souhaitons à présent tester l'hypothèse que l'impact de l'âge sur la probabilité d'utiliser le vélo varie d'un pays à l'autre. pour cela, nous allons ajuster des constantes aléatoires par Pays. Nous comparerons trois modèles, triés ici selon leur complexité (nombre de paramètre) : 

* Le modèle avec uniquement des constantes aléatoires
* Le modèle avec des des constantes et pentes aléatoires indépendantes
* Le modèle avec des des constantes et pentes aléatoires corrélées

Dans le *package* **lme4**, les syntaxes pour ajuster ces trois modèles sont les suivantes : 

* constantes aléatoires : `+(1|Pays)`
* constantes et pentes aléatoires indépendantes : `+(1 + Age||Pays)`
* constantes et pentes aléatoires corrélées: `+(1 + Age|Pays)`

Notez qu'il est aussi possible d'ajuster un modèle avec uniquement des pentes aléatoires avec la syntaxe : `+(-1 + Age|Pays)`. Le `-1` sert à explicitement retirer la constante aléatoire du modèle.

Ajustons donc nos deux modèles avec pentes et constantes aléatoires.
```{r, warning=FALSE, message=FALSE}

# constantes et pentes aléatoires indépendantes
modele2 <- glmer(y ~ Sexe + Age2 + Education + StatutEmploi + Revenu +
              Residence + Duree2 + ConsEnv + (1 + Age2||Pays),
            family = binomial(link="logit"),
            control = glmerControl(optimizer = "bobyqa"),
            data = dfenquete2)

# constantes et pentes aléatoires corrélées
modele3 <- glmer(y ~ Sexe + Age2 + Education + StatutEmploi + Revenu +
              Residence + Duree2 + ConsEnv + (1 + Age2|Pays),
            family = binomial(link="logit"),
            control = glmerControl(optimizer = "bobyqa"),
            data = dfenquete2)
```

#### Significativité de l'effet aléatoire

Puisque les trois modèles sont imbriqués, la première étape est de vérifier si les ajouts successifs au modèle de base sont significatifs, ce que nous pouvons tester avec un rapport de vraisemblance.

```{r, warning=FALSE, message=FALSE}
anova(modele1,modele2,modele3)
```

Nous constatons ainsi que l'ajout des pentes aléatoires permet d'améliorer significativement le modèle, mais que l'ajout de la corrélation entre les pentes et les constantes aléatoires a un apport très marginal. Nous décidons tout de même de le garder dans un premier temps car ce paramètre a un intérêt théorique. 

Affichons le résumé du modèle 3 : 

```{r, warning=FALSE, message=FALSE}
summary(modele3)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
var1 <- VarCorr(modele3)[[1]][[1]]
var2 <- VarCorr(modele3)[[1]][[4]]
var3 <- VarCorr(modele3)[[1]][[2]]
```
À nouveau, nous nous intéressons ici principalement à la section `Random Effect`, puisque les effets fixes s'interprètent exactement comme dans les modèles présentés dans le chapitre \@ref(chap06). Les constantes ont une variances de `r tofr(round(var1,3))` et les pentes de `r tofr(round(var2,3))`. La corrélation entre les deux effets est de `r tofr(round(var3 / (sqrt(var1)*sqrt(var2)),2))`. Cette corrélation est négative et relativement faible, ce qui signifie que les Pays dans lesquels la constante est forte, tendent à avoir des coefficients pour l'âge plus petits et donc une réduction accrue de la probabilité d'utiliser le vélo avec l'âge. Nous devons cependant encore nous assurer qu'elle est significativement différente de 0. Pour cela, nous devons calculer l'intervalle de confiance des trois paramètres de variance du modèle. Nous utilisons à nouveau une approche par bootstrap et nous enregistrons les résultats.

```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE}
# fonction d'extraction des trois paramètres de variance
extractor3 <- function(mod){
  vari1 <- VarCorr(mod)[[1]][[1]]
  vari2 <- VarCorr(mod)[[1]][[4]]
  covari <- VarCorr(mod)[[1]][[2]]
  return(c("vari1"=vari1,"vari2"=vari2,"covari"=covari))
}

# lancement du bootstrap
valeurs <- bootMer(modele3,FUN = extractor3,nsim = 1000,
                   use.u = F, type="parametric", ncpus = 8,
                   parallel="snow",
                   cl = cl,
                   .progress="txt",PBarg=list(style=3))

# enregistrement des résultats
save(valeurs,file = 'data/glmm/boot_binom3.rda')
```

À partir des valeurs bootstrapées, nous pouvons représenter les distributions de ces trois paramètres (variance des constantes, variance des pentes et corrélation entre les deux)
```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.cap="Incertitude autours des paramètres de variance obtenue par bootstrap", fig.align="center", out.width = "95%"}
# chargement des résultats
load('data/glmm/boot_binom3.rda')

# conversion des valeurs de covariance en corrélation
df <- data.frame(
  corr_values = valeurs$t[,3] / (sqrt(valeurs$t[,1]) * sqrt(valeurs$t[,2])),
  vari_const = valeurs$t[,1],
  vari_pente = valeurs$t[,2]
  )


# histogramme pour la variance des constantes
breaks1 <- quantile(df$vari_const,probs=c(0.025,0.5,0.975,0.999))
label1 <- round(breaks1,3)

p1 <- ggplot(df) + 
  geom_histogram(aes(x = vari_const), color = "black", fill = "white", bins = 30) + 
  geom_vline(xintercept = median(df$vari_const), color = "red", size = 1, linetype="dashed") + 
  geom_vline(xintercept = quantile(df$vari_const, probs = 0.025), color = "blue", size = 0.5, linetype="dashed") + 
  geom_vline(xintercept = quantile(df$vari_const, probs = 0.975), color = "blue", size = 0.5, linetype="dashed") + 
  labs(x = "Variance des constantes", y="")+ 
  scale_x_continuous(breaks = breaks1, labels = label1)

# histogramme pour la variance des pentes
breaks2 <- quantile(df$vari_pente,probs=c(0.025,0.5,0.975,0.999))
label2 <- round(breaks2,3)

p2 <- ggplot(df) + 
  geom_histogram(aes(x = vari_pente), color = "black", fill = "white", bins = 30) + 
  geom_vline(xintercept = median(df$vari_pente), color = "red", size = 1, linetype="dashed") + 
  geom_vline(xintercept = quantile(df$vari_pente, probs = 0.025), color = "blue", size = 0.5, linetype="dashed") + 
  geom_vline(xintercept = quantile(df$vari_pente, probs = 0.975), color = "blue", size = 0.5, linetype="dashed") + 
  labs(x = "Variance des pentes", y="")+
  scale_x_continuous(breaks = breaks2, labels = label2)

# histogramme pour la correlation
breaks3 <- c(-1,-0.5,0,0.5,1,median(df$corr_values))
label3 <- round(breaks3,3)

p3 <- ggplot(df) + 
  geom_histogram(aes(x = corr_values), color = "black", fill = "white", bins = 30) + 
  geom_vline(xintercept = median(df$corr_values), color = "red", size = 1, linetype="dashed") + 
  geom_vline(xintercept = quantile(df$corr_values, probs = 0.025), color = "blue", size = 0.5, linetype="dashed") + 
  geom_vline(xintercept = quantile(df$corr_values, probs = 0.975), color = "blue", size = 0.5, linetype="dashed") + 
  labs(x = "Corrélation pentes/constantes", y="") + 
  scale_x_continuous(breaks = breaks3, labels = label3)

ggarrange(p1,p2, p3, ncol = 2, nrow = 2)
```

Nous constatons ainsi que la variance des constantes aléatoire est significativement différentes de zéro (cette valeur ne se trouve pas dans l'intervalle de confiance à 95% représenté par les bordures bleues) et à une médiance de `tofr(round(df$vari_const,3))`. Pour les pentes, zéro est également à la limite de l'intervalle de confiance et la distribution asymétrique et étalée nous indique que ce paramètre est fortement incertain dans le modèle. Enfin, la corrélation entre les pentes et les constante est de loin le paramètre le plus incertain et son intervalle de confiance est franchement à cheval sur zéro, ce qui devrait nous amener à privilégier un modèle sans ce paramètre.

Pour terminer, nous pouvons calculer les R^2^ marginal et conditionnel du modèle afin de mieux cerner le rôle joué par les effets fixes et les effets aléatoires.
```{r, warning=FALSE, message=FALSE}
r.squaredGLMM(modele3)
```
Les valeurs des R^2^ marginal et conditionnel du modèle sont similaires à ceux que nous avions obtenus avec seulement des constantes aléatoires dans la section précédente, signalant l'apport relativement faible des pentes aléatoires

#### Analyse des effets aléatoires

Pour analyser facilement les constantes et pentes aléatoires de chaque pays, nous pouvons représenter graphiquement leurs intervalles de confiances construits à partir des simulations tirées de la distribution à postériori du modèle.

```{r randomconstantes2b, message=FALSE, warning=FALSE, out.width='70%',echo=T, fig.cap = "Constantes aléatoires estimées par Pays (IC par simulations)"}
# Simulations et extraction des effets aléatoires
library(merTools)
simsRE <- REsim(modele3,n.sims = 1000, oddsRatio = F)

# calcul des intervalles de confiance
simsRE$lower <- simsRE$mean - 1.96 * simsRE$sd
simsRE$upper <- simsRE$mean + 1.96 * simsRE$sd

# variable binaire pour la significativité
simsRE$sign <- case_when(
  simsRE$lower<0 & simsRE$upper<0 ~ "inf",
  simsRE$lower>0 & simsRE$upper>0 ~ "sup",
  TRUE ~ "not"
)

df1 <- subset(simsRE, grepl("Intercept",simsRE$term,fixed = T))
df2 <- subset(simsRE, grepl("Age2",simsRE$term,fixed = T))

# représentation des intervalles de confiance

p1 <- ggplot(df1) + 
  geom_errorbarh(aes(xmin = lower, xmax = upper,
                     y = reorder(groupID,mean)), size = 0.5, height = 0.5) + 
  geom_point(aes(x = mean, y = reorder(groupID,mean),
                 color = sign)) + 
  scale_color_manual(values = c("inf" = "#0077b6", "sup" = "#e63946", "not"="#000000"), labels = c("sign. < 0", "non sign.", "sign. > 0")) +
  labs(x = "Constante aléatoire", y = "Pays")

p2 <- ggplot(df2) + 
  geom_errorbarh(aes(xmin = lower, xmax = upper,
                     y = reorder(groupID,mean)), size = 0.5, height = 0.5) + 
  geom_point(aes(x = mean, y = reorder(groupID,mean),
                 color = sign)) + 
  scale_color_manual(values = c("inf" = "#0077b6", "sup" = "#e63946", "not"="#000000"), labels = c("sign. < 0", "non sign.", "sign. > 0")) +
  labs(x = "Pente aléatoire (âge)", y = "Pays")

ggarrange(p1,p2, common.legend = T, nrow = 1, ncol = 2)
```

La figure \@ref(fig:randomconstantes2b) nous permet ainsi de constater que l'effet des pays sur les pentes est presque toujours non significatif sauf pour le Danemark. Son effet négatif (`r tofr(round(ranef(modele3)$Pays[rownames(ranef(modele3)$Pays)=="Denmark",2],3))`) indique un renforcement de l'effet général lui même négatif (`r tofr(round(fixef(modele3)[[3]],3))`). Une interprétation possible est qu'au Danemark l'utilisation du vélo est plus proportionnellement plus utilisé par les jeunes que dans le reste des pays de l'UE.

Pour l'interprétation finale, il est nécessaire d'afficher les valeurs exactes de ces différents paramètres et dans notre cas de les convertir en rapport de cote avec la fonction exponentielle. Pour les pentes aléatoires, il peut être plus facile d'interpréter la somme de l'effet fixe et de l'effet aléatoire.

```{r}
# extraction des effets aléatoires obtenus par simulation
mat <- simsRE[c("mean","lower","upper")]
mat$Pays <- simsRE$groupID
mat$effet <- simsRE$term

# séparation des pentes et des constantes
df1 <- subset(mat, grepl("Intercept",mat$effet, fixed = TRUE))
df2 <- subset(mat, grepl("Age2",mat$effet, fixed = TRUE))

# conversion en rapport de cotes pour les pentes (+ effet fixe)
df2$RC <- round(exp(df2$mean + fixef(modele3)[[3]]),3)
df2$RC025 <- round(exp(df2$lower + fixef(modele3)[[3]]),3)
df2$RC975 <- round(exp(df2$upper + fixef(modele3)[[3]]),3)
print(head(df2[c("Pays","RC","RC025","RC975")],10))
```

Nous constatons ainsi qu'au Danemark, les chances pour un individu d'utiliser le vélo sont réduites de 20% à chaque augmentation de l'âge d'un écart type, contre seulement 1,5% en Autriche. Notons ici qu'un écart type de la variable Age est de 11 ans.

```{r}
# conversion en rapport de cotes pour les constantes
df1$RC <- round(exp(df1$mean),3)
df1$RC025 <- round(exp(df1$lower),3)
df1$RC975 <- round(exp(df1$upper),3)
print(head(df1[c("Pays","RC","RC025","RC975")],10))
```

En revanche, les chances pour un individu d'utiliser le vélo comme mode de transport pour son trajet le plus fréquent sont 4 fois supérieures à la moyenne européenne, contre seulement 1,3 fois en Autriche.

Notez à nouveau que les intervalles de confiances pour ces pentes et ces constantes pourraient être estimés plus fiablement par bootstrap.

#### Diagnostic des effets aléatoires

Pour rappel, dans un modèle GLMM, les effets aléatoires sont modélisés comme provenant de distribution aléatoires. Nous devons donc vérifier qu'ils respectent cette condition d'application. La figure \@ref(fig:diagbinomglmm1) (graphique quantile-quantile) nous permet de constater que les constantes suivent bien une distribution normale, ce qui ne semble pas vraiment être le cas pour les pentes. Consiédrant que leurs effets sont petits, il pourrait être plus pertinent ici de les retirer du modèle.

```{r diagbinomglmm1, echo = FALSE, fig.align='center', fig.cap="Distribution normale univariée des constantes et pentes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='90%'}

df <- data.frame(ranef(modele3)$Pays)
names(df) <- c('constante',"pente")

p1 <- qplot(sample = df$constante)+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(title="Diagramme quantile-quantile",
     x="Valeurs théoriques",
     y = "Constantes aléatoires")

p2 <- qplot(sample = df$pente)+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(title="Diagramme quantile-quantile",
     x="Valeurs théoriques",
     y = "Pentes aléatoires")

ggarrange(p1,p2, common.legend = T, nrow = 1, ncol = 2)
```

Considérant que ce modèle inclue une corrélation entre les constantes et les pentes aléatoires, il est également nécessaire de vérifier si elles suivent conjointement une distribution normale bivariée. La figure \@ref(fig:diagbinomglmm2) semble indiquer 

```{r diagbinomglmm2, echo = TRUE, fig.align='center', fig.cap="Distribution normale bivariée des constantes et pentes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
cor_mat <- VarCorr(modele3)[[1]]

re_effects <- data.frame(ranef(modele3)$Pays)
names(re_effects) <- c("constante","pente")

library(ellipse)

levels <- c(0.05,0.25,0.75,0.95)

els <- lapply(levels, function(i){
  el <- data.frame(ellipse(cor_mat,center = c(0,0), level = i))
  names(el) <- c("x","y")
  return(el)
})

ref_points <- data.frame(data.frame(MASS::mvrnorm(n = 1000, mu = c(0,0), Sigma = cor_mat)))
names(ref_points) <- c("x","y")

ggplot() + 
  geom_point(aes(x = x, y = y), data = ref_points, alpha = 0.3, size = 0.4) + 
  geom_path(data = els[[1]], aes(x = x, y = y, color = "a")) + 
  geom_path(data = els[[2]], aes(x = x, y = y, color = "b")) + 
  geom_path(data = els[[3]], aes(x = x, y = y, color = "c")) +
  geom_path(data = els[[4]], aes(x = x, y = y, color = "d")) + 
  geom_point(data = re_effects, aes(x = constante, y = pente))+
  scale_color_manual(values = c("a"="#90e0ef",
                                "b"="#00b4d8",
                                "c"="#0077b6",
                                "d"="#03045e"),
                     labels = c("5%","25%","75%","95%"))+
  labs(x = "Constantes", y = "Pentes")
```

#### Inférence pour les effets fixes

Nous avions mentionné dans les sections précédentes que le calcul de valeurs de *P* pour les effets fixes fait l'objet de controverse dans les modèles GLMM. La méthode offrant le meilleur compromis entre rapidité de calcul et fiabilité est la méthode Satterthwaite implémantée dans le *package* **lmerTest**. Pour l'utiliser, il suffit simplement de charger le *package* **lmerTest** après **lme4**, ce qui modifiera la fonction `summary` pour qu'elle utilise directement cette approche.

```{r diagbinomglmm3, message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(lmerTest)
round(summary(modele3)$coefficients,3)
```

Les deux autres options envisageables sont : 

* Effectuer une analyse de type 3
* Calculer les intervalles de confiance par bootstrap

Cependant elles requierent beaucoup plus de temps de calcul et ne sont donc pas présentées ici.

## Régressions multiniveaux {#sect074}
